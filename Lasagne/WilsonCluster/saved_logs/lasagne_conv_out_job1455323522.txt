PBS prologue
Job lasagne-conv-mnv submitted from mic.fnal.gov started Fri Feb 12 18:32:03 CST 2016 jobid 104800.tev.fnal.gov
gpu1
PBS_O_WORKDIR is /home/perdue/ANNMINERvA/WilsonCluster
Git repo version is 2136c1da0c76
Using gpu device 0: Tesla K20m (CNMeM is disabled)
/usr/local/python2/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.
  warnings.warn("downsample module has been moved to the pool module.")
Starting...
 Begin with saved parameters? False
 Saved parameters file: ./lminervatriamese_model.npz
 Saved parameters file exists? True
 Dataset: /phihome/perdue/theano/data/skim_data_convnet.hdf5
 Dataset size: 240004328
 Planned number of epochs: 200
 Learning rate: 0.001
 Momentum: 0.9
Loading data...
Learning data size: (159495, 3, 50, 50)

In -->         Layer    --> Out    Description                                                  
-------        -----    -------    -----------                                                  
[]             0        [1]        <lasagne.layers.input.InputLayer object at 0x2ad85043f4d0>   
[0]            1        [2]        <lasagne.layers.conv.Conv2DLayer object at 0x2ad85043f5d0>   
[1]            2        [3]        <lasagne.layers.pool.MaxPool2DLayer object at 0x2ad85043f590>
[2]            3        [4]        <lasagne.layers.conv.Conv2DLayer object at 0x2ad85045ea50>   
[3]            4        [5]        <lasagne.layers.pool.MaxPool2DLayer object at 0x2ad85045ead0>
[4]            5        [6]        <lasagne.layers.noise.DropoutLayer object at 0x2ad850470350> 
[5]            6        [21]       <lasagne.layers.dense.DenseLayer object at 0x2ad850470390>   
[]             7        [8]        <lasagne.layers.input.InputLayer object at 0x2ad85043f510>   
[7]            8        [9]        <lasagne.layers.conv.Conv2DLayer object at 0x2ad85043f610>   
[8]            9        [10]       <lasagne.layers.pool.MaxPool2DLayer object at 0x2ad85045e810>
[9]            10       [11]       <lasagne.layers.conv.Conv2DLayer object at 0x2ad85045eb10>   
[10]           11       [12]       <lasagne.layers.pool.MaxPool2DLayer object at 0x2ad850470050>
[11]           12       [13]       <lasagne.layers.noise.DropoutLayer object at 0x2ad8504703d0> 
[12]           13       [21]       <lasagne.layers.dense.DenseLayer object at 0x2ad850470a50>   
[]             14       [15]       <lasagne.layers.input.InputLayer object at 0x2ad85043f550>   
[14]           15       [16]       <lasagne.layers.conv.Conv2DLayer object at 0x2ad85045e590>   
[15]           16       [17]       <lasagne.layers.pool.MaxPool2DLayer object at 0x2ad85045ea90>
[16]           17       [18]       <lasagne.layers.conv.Conv2DLayer object at 0x2ad85045edd0>   
[17]           18       [19]       <lasagne.layers.pool.MaxPool2DLayer object at 0x2ad850470310>
[18]           19       [20]       <lasagne.layers.noise.DropoutLayer object at 0x2ad8504709d0> 
[19]           20       [21]       <lasagne.layers.dense.DenseLayer object at 0x2ad850470d50>   
[6, 13, 20]    21       [22]       <lasagne.layers.merge.ConcatLayer object at 0x2ad850470cd0>  
[21]           22       [23]       <lasagne.layers.noise.DropoutLayer object at 0x2ad850470fd0> 
[22]           23       []         <lasagne.layers.dense.DenseLayer object at 0x2ad9b4e8b090>   
Starting training...
Epoch 1 of 200 took 266.022s
  training loss:		2.257754
  validation loss:		2.207630
  validation accuracy:		22.03 %
Epoch 2 of 200 took 265.602s
  training loss:		2.225809
  validation loss:		2.204390
  validation accuracy:		22.03 %
Epoch 3 of 200 took 266.069s
  training loss:		2.217583
  validation loss:		2.196576
  validation accuracy:		22.03 %
Epoch 4 of 200 took 265.969s
  training loss:		2.207725
  validation loss:		2.181653
  validation accuracy:		22.03 %
Epoch 5 of 200 took 265.879s
  training loss:		2.191477
  validation loss:		2.156738
  validation accuracy:		24.50 %
Epoch 6 of 200 took 265.861s
  training loss:		2.157899
  validation loss:		2.105925
  validation accuracy:		35.63 %
Epoch 7 of 200 took 265.674s
  training loss:		2.077589
  validation loss:		1.970295
  validation accuracy:		37.15 %
Epoch 8 of 200 took 265.615s
  training loss:		1.925973
  validation loss:		1.796592
  validation accuracy:		42.05 %
Epoch 9 of 200 took 265.576s
  training loss:		1.746035
  validation loss:		1.572406
  validation accuracy:		47.13 %
Epoch 10 of 200 took 265.648s
  training loss:		1.608986
  validation loss:		1.468949
  validation accuracy:		49.18 %
Epoch 11 of 200 took 265.638s
  training loss:		1.535394
  validation loss:		1.393119
  validation accuracy:		51.27 %
Epoch 12 of 200 took 266.245s
  training loss:		1.484607
  validation loss:		1.370426
  validation accuracy:		51.92 %
Epoch 13 of 200 took 266.358s
  training loss:		1.450585
  validation loss:		1.328710
  validation accuracy:		52.90 %
Epoch 14 of 200 took 265.604s
  training loss:		1.419032
  validation loss:		1.314578
  validation accuracy:		53.40 %
Epoch 15 of 200 took 265.700s
  training loss:		1.393545
  validation loss:		1.279341
  validation accuracy:		54.59 %
Epoch 16 of 200 took 266.075s
  training loss:		1.373556
  validation loss:		1.282436
  validation accuracy:		54.35 %
Epoch 17 of 200 took 266.243s
  training loss:		1.357098
  validation loss:		1.243165
  validation accuracy:		55.64 %
Epoch 18 of 200 took 266.041s
  training loss:		1.348031
  validation loss:		1.246742
  validation accuracy:		55.44 %
Epoch 19 of 200 took 266.058s
  training loss:		1.326326
  validation loss:		1.217157
  validation accuracy:		56.42 %
Epoch 20 of 200 took 266.100s
  training loss:		1.306484
  validation loss:		1.212376
  validation accuracy:		56.69 %
Epoch 21 of 200 took 266.074s
  training loss:		1.301809
  validation loss:		1.199648
  validation accuracy:		57.07 %
Epoch 22 of 200 took 266.024s
  training loss:		1.283634
  validation loss:		1.199236
  validation accuracy:		57.30 %
Epoch 23 of 200 took 266.083s
  training loss:		1.272394
  validation loss:		1.177318
  validation accuracy:		57.97 %
Epoch 24 of 200 took 266.066s
  training loss:		1.263137
  validation loss:		1.178149
  validation accuracy:		57.94 %
Epoch 25 of 200 took 265.958s
  training loss:		1.252739
  validation loss:		1.163162
  validation accuracy:		58.28 %
Epoch 26 of 200 took 266.099s
  training loss:		1.246615
  validation loss:		1.148975
  validation accuracy:		58.98 %
Epoch 27 of 200 took 266.015s
  training loss:		1.233450
  validation loss:		1.139401
  validation accuracy:		59.44 %
Epoch 28 of 200 took 266.057s
  training loss:		1.230497
  validation loss:		1.128401
  validation accuracy:		59.66 %
Epoch 29 of 200 took 266.065s
  training loss:		1.220265
  validation loss:		1.117700
  validation accuracy:		59.90 %
Epoch 30 of 200 took 266.008s
  training loss:		1.208901
  validation loss:		1.112984
  validation accuracy:		60.18 %
Epoch 31 of 200 took 266.107s
  training loss:		1.196697
  validation loss:		1.104360
  validation accuracy:		60.42 %
Epoch 32 of 200 took 266.074s
  training loss:		1.189271
  validation loss:		1.095880
  validation accuracy:		60.66 %
Epoch 33 of 200 took 266.875s
  training loss:		1.183454
  validation loss:		1.090047
  validation accuracy:		60.84 %
Epoch 34 of 200 took 266.032s
  training loss:		1.177185
  validation loss:		1.084110
  validation accuracy:		61.14 %
Epoch 35 of 200 took 265.985s
  training loss:		1.174680
  validation loss:		1.081994
  validation accuracy:		61.46 %
Epoch 36 of 200 took 266.417s
  training loss:		1.165322
  validation loss:		1.075375
  validation accuracy:		61.61 %
Epoch 37 of 200 took 266.618s
  training loss:		1.157809
  validation loss:		1.066528
  validation accuracy:		61.65 %
Epoch 38 of 200 took 266.140s
  training loss:		1.150675
  validation loss:		1.059920
  validation accuracy:		61.98 %
Epoch 39 of 200 took 266.568s
  training loss:		1.144385
  validation loss:		1.057198
  validation accuracy:		62.09 %
Epoch 40 of 200 took 266.109s
  training loss:		1.140355
  validation loss:		1.057084
  validation accuracy:		62.31 %
Epoch 41 of 200 took 266.028s
  training loss:		1.132211
  validation loss:		1.046683
  validation accuracy:		62.53 %
Epoch 42 of 200 took 266.082s
  training loss:		1.128754
  validation loss:		1.042056
  validation accuracy:		62.84 %
Epoch 43 of 200 took 266.007s
  training loss:		1.122873
  validation loss:		1.036183
  validation accuracy:		63.07 %
Epoch 44 of 200 took 266.126s
  training loss:		1.115919
  validation loss:		1.040594
  validation accuracy:		63.02 %
Epoch 45 of 200 took 266.618s
  training loss:		1.116432
  validation loss:		1.026964
  validation accuracy:		63.27 %
Epoch 46 of 200 took 266.435s
  training loss:		1.106965
  validation loss:		1.024404
  validation accuracy:		63.53 %
Epoch 47 of 200 took 266.042s
  training loss:		1.102899
  validation loss:		1.017263
  validation accuracy:		63.73 %
Epoch 48 of 200 took 266.143s
  training loss:		1.097640
  validation loss:		1.015005
  validation accuracy:		63.96 %
Epoch 49 of 200 took 266.156s
  training loss:		1.093946
  validation loss:		1.011085
  validation accuracy:		63.95 %
Epoch 50 of 200 took 266.129s
  training loss:		1.091121
  validation loss:		1.005598
  validation accuracy:		64.26 %
Epoch 51 of 200 took 266.085s
  training loss:		1.084958
  validation loss:		1.000429
  validation accuracy:		64.53 %
Epoch 52 of 200 took 266.057s
  training loss:		1.078284
  validation loss:		0.994259
  validation accuracy:		64.55 %
Epoch 53 of 200 took 266.092s
  training loss:		1.076112
  validation loss:		0.995673
  validation accuracy:		64.86 %
Epoch 54 of 200 took 266.048s
  training loss:		1.075901
  validation loss:		0.992053
  validation accuracy:		64.83 %
Epoch 55 of 200 took 266.453s
  training loss:		1.081528
  validation loss:		0.997832
  validation accuracy:		64.79 %
Epoch 56 of 200 took 266.111s
  training loss:		1.065894
  validation loss:		0.984953
  validation accuracy:		65.36 %
Epoch 57 of 200 took 266.215s
  training loss:		1.066676
  validation loss:		0.977818
  validation accuracy:		65.43 %
Epoch 58 of 200 took 266.109s
  training loss:		1.055629
  validation loss:		0.976851
  validation accuracy:		65.65 %
Epoch 59 of 200 took 266.407s
  training loss:		1.051234
  validation loss:		0.974052
  validation accuracy:		65.81 %
Epoch 60 of 200 took 266.349s
  training loss:		1.047918
  validation loss:		0.970953
  validation accuracy:		65.91 %
Epoch 61 of 200 took 266.305s
  training loss:		1.043237
  validation loss:		0.966758
  validation accuracy:		66.20 %
Epoch 62 of 200 took 266.151s
  training loss:		1.038233
  validation loss:		0.961006
  validation accuracy:		66.37 %
Epoch 63 of 200 took 266.125s
  training loss:		1.037916
  validation loss:		0.962382
  validation accuracy:		66.46 %
Epoch 64 of 200 took 266.566s
  training loss:		1.032459
  validation loss:		0.956625
  validation accuracy:		66.62 %
Epoch 65 of 200 took 266.041s
  training loss:		1.027137
  validation loss:		0.950236
  validation accuracy:		66.77 %
Epoch 66 of 200 took 266.024s
  training loss:		1.025037
  validation loss:		0.947126
  validation accuracy:		66.77 %
Epoch 67 of 200 took 266.093s
  training loss:		1.021809
  validation loss:		0.945189
  validation accuracy:		67.05 %
Epoch 68 of 200 took 266.131s
  training loss:		1.025057
  validation loss:		0.953214
  validation accuracy:		66.78 %
Epoch 69 of 200 took 266.008s
  training loss:		1.014651
  validation loss:		0.941122
  validation accuracy:		67.41 %
Epoch 70 of 200 took 266.016s
  training loss:		1.010963
  validation loss:		0.936333
  validation accuracy:		67.50 %
Epoch 71 of 200 took 266.058s
  training loss:		1.008576
  validation loss:		0.935447
  validation accuracy:		67.66 %
Epoch 72 of 200 took 266.057s
  training loss:		1.007740
  validation loss:		0.930600
  validation accuracy:		67.74 %
Epoch 73 of 200 took 265.993s
  training loss:		1.006855
  validation loss:		0.941135
  validation accuracy:		67.59 %
Epoch 74 of 200 took 266.051s
  training loss:		1.001589
  validation loss:		0.925586
  validation accuracy:		68.02 %
Epoch 75 of 200 took 266.044s
  training loss:		0.998537
  validation loss:		0.922669
  validation accuracy:		68.06 %
Epoch 76 of 200 took 266.150s
  training loss:		0.995020
  validation loss:		0.919882
  validation accuracy:		68.18 %
Epoch 77 of 200 took 266.033s
  training loss:		0.991089
  validation loss:		0.918887
  validation accuracy:		68.47 %
Epoch 78 of 200 took 266.081s
  training loss:		0.988451
  validation loss:		0.914550
  validation accuracy:		68.64 %
Epoch 79 of 200 took 266.072s
  training loss:		0.982554
  validation loss:		0.911992
  validation accuracy:		68.87 %
Epoch 80 of 200 took 266.084s
  training loss:		0.984044
  validation loss:		0.909974
  validation accuracy:		68.83 %
Epoch 81 of 200 took 266.083s
  training loss:		0.982584
  validation loss:		0.908416
  validation accuracy:		68.94 %
Epoch 82 of 200 took 266.140s
  training loss:		0.983051
  validation loss:		0.907197
  validation accuracy:		68.98 %
Epoch 83 of 200 took 266.085s
  training loss:		0.976920
  validation loss:		0.902872
  validation accuracy:		69.15 %
Epoch 84 of 200 took 266.163s
  training loss:		0.972431
  validation loss:		0.901993
  validation accuracy:		69.23 %
Epoch 85 of 200 took 266.117s
  training loss:		0.972269
  validation loss:		0.897316
  validation accuracy:		69.39 %
Epoch 86 of 200 took 266.048s
  training loss:		0.966674
  validation loss:		0.897649
  validation accuracy:		69.36 %
Epoch 87 of 200 took 265.940s
  training loss:		0.964491
  validation loss:		0.894596
  validation accuracy:		69.58 %
Epoch 88 of 200 took 266.057s
  training loss:		0.961816
  validation loss:		0.892520
  validation accuracy:		69.59 %
Epoch 89 of 200 took 266.057s
  training loss:		0.960677
  validation loss:		0.889331
  validation accuracy:		69.78 %
Epoch 90 of 200 took 266.092s
  training loss:		0.957810
  validation loss:		0.887568
  validation accuracy:		69.77 %
Epoch 91 of 200 took 265.932s
  training loss:		0.956514
  validation loss:		0.884492
  validation accuracy:		69.84 %
Epoch 92 of 200 took 266.152s
  training loss:		0.953541
  validation loss:		0.883243
  validation accuracy:		70.08 %
Epoch 93 of 200 took 266.120s
  training loss:		0.950487
  validation loss:		0.881383
  validation accuracy:		70.21 %
Epoch 94 of 200 took 266.039s
  training loss:		0.949421
  validation loss:		0.881211
  validation accuracy:		70.23 %
Epoch 95 of 200 took 266.177s
  training loss:		0.947169
  validation loss:		0.879539
  validation accuracy:		70.33 %
Epoch 96 of 200 took 266.099s
  training loss:		0.947396
  validation loss:		0.877450
  validation accuracy:		70.50 %
Epoch 97 of 200 took 266.090s
  training loss:		0.942930
  validation loss:		0.877445
  validation accuracy:		70.27 %
Epoch 98 of 200 took 266.053s
  training loss:		0.948447
  validation loss:		0.873057
  validation accuracy:		70.49 %
Epoch 99 of 200 took 266.103s
  training loss:		0.938480
  validation loss:		0.871605
  validation accuracy:		70.48 %
Epoch 100 of 200 took 266.000s
  training loss:		0.937987
  validation loss:		0.870549
  validation accuracy:		70.48 %
Epoch 101 of 200 took 266.360s
  training loss:		0.934374
  validation loss:		0.870101
  validation accuracy:		70.76 %
Epoch 102 of 200 took 266.274s
  training loss:		0.933065
  validation loss:		0.865283
  validation accuracy:		70.79 %
Epoch 103 of 200 took 266.179s
  training loss:		0.932375
  validation loss:		0.863977
  validation accuracy:		70.92 %
Epoch 104 of 200 took 266.074s
  training loss:		0.931809
  validation loss:		0.863045
  validation accuracy:		70.99 %
Epoch 105 of 200 took 266.542s
  training loss:		0.927825
  validation loss:		0.860475
  validation accuracy:		71.14 %
Epoch 106 of 200 took 266.157s
  training loss:		0.925060
  validation loss:		0.859140
  validation accuracy:		71.12 %
Epoch 107 of 200 took 266.573s
  training loss:		0.922638
  validation loss:		0.857785
  validation accuracy:		71.13 %
Epoch 108 of 200 took 266.765s
  training loss:		0.922404
  validation loss:		0.856675
  validation accuracy:		71.26 %
Epoch 109 of 200 took 266.440s
  training loss:		0.917652
  validation loss:		0.854803
  validation accuracy:		71.30 %
Epoch 110 of 200 took 266.257s
  training loss:		0.919563
  validation loss:		0.852291
  validation accuracy:		71.47 %
Epoch 111 of 200 took 266.265s
  training loss:		0.917880
  validation loss:		0.850960
  validation accuracy:		71.30 %
Epoch 112 of 200 took 267.074s
  training loss:		0.914038
  validation loss:		0.852578
  validation accuracy:		71.47 %
Epoch 113 of 200 took 266.724s
  training loss:		0.911973
  validation loss:		0.847069
  validation accuracy:		71.58 %
Epoch 114 of 200 took 266.067s
  training loss:		0.911196
  validation loss:		0.845948
  validation accuracy:		71.61 %
Epoch 115 of 200 took 266.108s
  training loss:		0.908480
  validation loss:		0.845030
  validation accuracy:		71.64 %
Epoch 116 of 200 took 266.114s
  training loss:		0.905335
  validation loss:		0.842824
  validation accuracy:		71.82 %
Epoch 117 of 200 took 266.041s
  training loss:		0.906259
  validation loss:		0.841403
  validation accuracy:		71.90 %
Epoch 118 of 200 took 266.163s
  training loss:		0.904088
  validation loss:		0.839695
  validation accuracy:		71.91 %
Epoch 119 of 200 took 266.002s
  training loss:		0.902656
  validation loss:		0.838958
  validation accuracy:		71.93 %
Epoch 120 of 200 took 266.034s
  training loss:		0.901475
  validation loss:		0.838512
  validation accuracy:		71.86 %
Epoch 121 of 200 took 266.057s
  training loss:		0.900224
  validation loss:		0.835195
  validation accuracy:		71.98 %
Epoch 122 of 200 took 266.118s
  training loss:		0.896771
  validation loss:		0.833391
  validation accuracy:		72.06 %
Epoch 123 of 200 took 266.118s
  training loss:		0.894540
  validation loss:		0.833462
  validation accuracy:		72.14 %
Epoch 124 of 200 took 266.069s
  training loss:		0.893351
  validation loss:		0.829980
  validation accuracy:		72.05 %
Epoch 125 of 200 took 266.157s
  training loss:		0.891716
  validation loss:		0.830122
  validation accuracy:		72.26 %
Epoch 126 of 200 took 266.117s
  training loss:		0.891570
  validation loss:		0.827866
  validation accuracy:		72.38 %
Epoch 127 of 200 took 266.058s
  training loss:		0.889402
  validation loss:		0.828601
  validation accuracy:		72.22 %
Epoch 128 of 200 took 266.041s
  training loss:		0.888934
  validation loss:		0.824363
  validation accuracy:		72.34 %
Epoch 129 of 200 took 266.180s
  training loss:		0.884921
  validation loss:		0.823810
  validation accuracy:		72.35 %
Epoch 130 of 200 took 266.093s
  training loss:		0.885760
  validation loss:		0.822657
  validation accuracy:		72.37 %
Epoch 131 of 200 took 266.117s
  training loss:		0.883442
  validation loss:		0.821418
  validation accuracy:		72.49 %
Epoch 132 of 200 took 266.116s
  training loss:		0.882187
  validation loss:		0.819647
  validation accuracy:		72.44 %
Epoch 133 of 200 took 266.041s
  training loss:		0.880401
  validation loss:		0.818014
  validation accuracy:		72.56 %
Epoch 134 of 200 took 266.015s
  training loss:		0.876427
  validation loss:		0.816751
  validation accuracy:		72.67 %
Epoch 135 of 200 took 266.143s
  training loss:		0.875638
  validation loss:		0.816485
  validation accuracy:		72.66 %
Epoch 136 of 200 took 266.510s
  training loss:		0.875401
  validation loss:		0.813735
  validation accuracy:		72.72 %
Epoch 137 of 200 took 266.155s
  training loss:		0.873585
  validation loss:		0.813102
  validation accuracy:		72.66 %
Epoch 138 of 200 took 266.784s
  training loss:		0.870244
  validation loss:		0.811158
  validation accuracy:		72.75 %
Epoch 139 of 200 took 266.840s
  training loss:		0.871887
  validation loss:		0.809360
  validation accuracy:		72.84 %
Epoch 140 of 200 took 266.208s
  training loss:		0.868977
  validation loss:		0.809612
  validation accuracy:		72.91 %
Epoch 141 of 200 took 266.065s
  training loss:		0.866573
  validation loss:		0.808389
  validation accuracy:		72.90 %
Epoch 142 of 200 took 266.907s
  training loss:		0.866016
  validation loss:		0.805588
  validation accuracy:		72.99 %
Epoch 143 of 200 took 266.400s
  training loss:		0.864311
  validation loss:		0.805358
  validation accuracy:		72.97 %
Epoch 144 of 200 took 266.152s
  training loss:		0.863770
  validation loss:		0.806300
  validation accuracy:		73.04 %
Epoch 145 of 200 took 266.034s
  training loss:		0.860608
  validation loss:		0.802227
  validation accuracy:		73.08 %
Epoch 146 of 200 took 266.067s
  training loss:		0.860524
  validation loss:		0.800643
  validation accuracy:		73.11 %
Epoch 147 of 200 took 266.126s
  training loss:		0.856812
  validation loss:		0.800317
  validation accuracy:		73.22 %
Epoch 148 of 200 took 266.008s
  training loss:		0.853640
  validation loss:		0.798557
  validation accuracy:		73.21 %
Epoch 149 of 200 took 266.134s
  training loss:		0.854100
  validation loss:		0.795320
  validation accuracy:		73.40 %
Epoch 150 of 200 took 266.172s
  training loss:		0.853175
  validation loss:		0.795784
  validation accuracy:		73.46 %
Epoch 151 of 200 took 266.224s
  training loss:		0.851003
  validation loss:		0.793153
  validation accuracy:		73.40 %
Epoch 152 of 200 took 266.072s
  training loss:		0.851021
  validation loss:		0.791901
  validation accuracy:		73.53 %
Epoch 153 of 200 took 266.052s
  training loss:		0.846125
  validation loss:		0.790800
  validation accuracy:		73.51 %
Epoch 154 of 200 took 265.974s
  training loss:		0.848102
  validation loss:		0.789042
  validation accuracy:		73.50 %
Epoch 155 of 200 took 266.235s
  training loss:		0.846640
  validation loss:		0.788828
  validation accuracy:		73.48 %
Epoch 156 of 200 took 266.075s
  training loss:		0.842036
  validation loss:		0.786257
  validation accuracy:		73.64 %
Epoch 157 of 200 took 266.093s
  training loss:		0.841471
  validation loss:		0.786441
  validation accuracy:		73.75 %
Epoch 158 of 200 took 266.059s
  training loss:		0.841229
  validation loss:		0.784158
  validation accuracy:		73.71 %
Epoch 159 of 200 took 266.049s
  training loss:		0.839157
  validation loss:		0.783178
  validation accuracy:		73.77 %
Epoch 160 of 200 took 266.285s
  training loss:		0.835433
  validation loss:		0.780766
  validation accuracy:		73.83 %
Epoch 161 of 200 took 266.077s
  training loss:		0.835736
  validation loss:		0.778683
  validation accuracy:		73.86 %
Epoch 162 of 200 took 266.020s
  training loss:		0.834143
  validation loss:		0.777957
  validation accuracy:		73.97 %
Epoch 163 of 200 took 266.032s
  training loss:		0.832794
  validation loss:		0.776685
  validation accuracy:		73.95 %
Epoch 164 of 200 took 266.124s
  training loss:		0.832709
  validation loss:		0.775052
  validation accuracy:		74.09 %
Epoch 165 of 200 took 266.092s
  training loss:		0.830964
  validation loss:		0.775488
  validation accuracy:		74.08 %
Epoch 166 of 200 took 266.027s
  training loss:		0.830512
  validation loss:		0.773984
  validation accuracy:		74.14 %
Epoch 167 of 200 took 266.046s
  training loss:		0.827340
  validation loss:		0.772860
  validation accuracy:		74.18 %
Epoch 168 of 200 took 266.032s
  training loss:		0.825017
  validation loss:		0.769881
  validation accuracy:		74.33 %
Epoch 169 of 200 took 266.016s
  training loss:		0.824307
  validation loss:		0.769338
  validation accuracy:		74.23 %
Epoch 170 of 200 took 266.208s
  training loss:		0.822790
  validation loss:		0.767775
  validation accuracy:		74.36 %
Epoch 171 of 200 took 266.100s
  training loss:		0.822907
  validation loss:		0.766291
  validation accuracy:		74.47 %
Epoch 172 of 200 took 266.003s
  training loss:		0.819668
  validation loss:		0.765118
  validation accuracy:		74.43 %
Epoch 173 of 200 took 265.950s
  training loss:		0.818737
  validation loss:		0.764291
  validation accuracy:		74.50 %
Epoch 174 of 200 took 266.295s
  training loss:		0.816622
  validation loss:		0.763497
  validation accuracy:		74.55 %
Epoch 175 of 200 took 266.065s
  training loss:		0.815530
  validation loss:		0.759869
  validation accuracy:		74.57 %
Epoch 176 of 200 took 266.799s
  training loss:		0.814253
  validation loss:		0.761259
  validation accuracy:		74.62 %
Epoch 177 of 200 took 266.382s
  training loss:		0.812772
  validation loss:		0.758694
  validation accuracy:		74.60 %
Epoch 178 of 200 took 266.078s
  training loss:		0.811384
  validation loss:		0.757085
  validation accuracy:		74.68 %
Epoch 179 of 200 took 266.079s
  training loss:		0.809889
  validation loss:		0.755276
  validation accuracy:		74.72 %
Epoch 180 of 200 took 266.082s
  training loss:		0.808675
  validation loss:		0.753257
  validation accuracy:		74.74 %
Epoch 181 of 200 took 266.057s
  training loss:		0.807665
  validation loss:		0.754957
  validation accuracy:		74.72 %
Epoch 182 of 200 took 266.076s
  training loss:		0.804391
  validation loss:		0.751027
  validation accuracy:		74.81 %
Epoch 183 of 200 took 266.093s
  training loss:		0.804773
  validation loss:		0.750372
  validation accuracy:		74.87 %
Epoch 184 of 200 took 266.759s
  training loss:		0.804196
  validation loss:		0.749303
  validation accuracy:		74.82 %
Epoch 185 of 200 took 266.259s
  training loss:		0.802991
  validation loss:		0.747359
  validation accuracy:		74.93 %
Epoch 186 of 200 took 265.968s
  training loss:		0.798664
  validation loss:		0.746768
  validation accuracy:		75.08 %
Epoch 187 of 200 took 266.077s
  training loss:		0.800086
  validation loss:		0.745043
  validation accuracy:		74.98 %
Epoch 188 of 200 took 266.180s
  training loss:		0.797718
  validation loss:		0.743828
  validation accuracy:		74.99 %
Epoch 189 of 200 took 266.099s
  training loss:		0.796049
  validation loss:		0.741951
  validation accuracy:		75.17 %
Epoch 190 of 200 took 266.157s
  training loss:		0.795361
  validation loss:		0.740627
  validation accuracy:		75.21 %
Epoch 191 of 200 took 266.217s
  training loss:		0.792718
  validation loss:		0.739694
  validation accuracy:		75.32 %
Epoch 192 of 200 took 266.299s
  training loss:		0.792559
  validation loss:		0.738750
  validation accuracy:		75.23 %
Epoch 193 of 200 took 266.036s
  training loss:		0.790802
  validation loss:		0.738193
  validation accuracy:		75.27 %
Epoch 194 of 200 took 266.028s
  training loss:		0.788847
  validation loss:		0.737223
  validation accuracy:		75.31 %
Epoch 195 of 200 took 266.154s
  training loss:		0.789143
  validation loss:		0.735143
  validation accuracy:		75.39 %
Epoch 196 of 200 took 266.019s
  training loss:		0.787407
  validation loss:		0.734734
  validation accuracy:		75.39 %
Epoch 197 of 200 took 266.009s
  training loss:		0.784963
  validation loss:		0.733514
  validation accuracy:		75.34 %
Epoch 198 of 200 took 265.999s
  training loss:		0.784881
  validation loss:		0.733443
  validation accuracy:		75.52 %
Epoch 199 of 200 took 265.974s
  training loss:		0.783553
  validation loss:		0.733352
  validation accuracy:		75.58 %
Epoch 200 of 200 took 266.063s
  training loss:		0.783004
  validation loss:		0.729736
  validation accuracy:		75.45 %
Final results:
  test loss:			0.732923
  test accuracy:		75.19 %
PBS epilogue
