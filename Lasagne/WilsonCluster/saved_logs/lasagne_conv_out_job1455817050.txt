PBS prologue
Job lasagne-conv-mnv submitted from mic.fnal.gov started Thu Feb 18 11:37:31 CST 2016 jobid 105128.tev.fnal.gov
gpu1
PBS_O_WORKDIR is /home/perdue/ANNMINERvA/WilsonCluster
Git repo version is db43638c5257-dirty
Git repo contains uncomitted changes! Please commit your changes
before submitting a job. If you feel your changes are experimental,
just use a feature branch.

Changed files:
Lasagne/lasagne_triamese_minerva.py
WilsonCluster/job_lasagne_conv_mlp.sh

Using gpu device 0: Tesla K20m (CNMeM is disabled)
/usr/local/python2/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.
  warnings.warn("downsample module has been moved to the pool module.")
Starting...
 Begin with saved parameters? False
 Saved parameters file: ./lminervatriamese_model1455817051.npz
 Saved parameters file exists? False
 Dataset: /phihome/perdue/theano/data/skim_data_convnet_small.hdf5
 Dataset size: 120041441
 Planned number of epochs: 2
 Learning rate: 0.01
 Momentum: 0.9
 L2 regularization penalty scale: 0.0
Loading data...
Learning data size: (79775, 3, 50, 50)

In -->         Layer    --> Out    Description                                                  
-------        -----    -------    -----------                                                  
[]             0        [1]        <lasagne.layers.input.InputLayer object at 0x2b7eaf8bb510>   
[0]            1        [2]        <lasagne.layers.conv.Conv2DLayer object at 0x2b7eaf8bb610>   
[1]            2        [3]        <lasagne.layers.pool.MaxPool2DLayer object at 0x2b7eaf8bb5d0>
[2]            3        [4]        <lasagne.layers.conv.Conv2DLayer object at 0x2b7eaf8d9a90>   
[3]            4        [5]        <lasagne.layers.pool.MaxPool2DLayer object at 0x2b7eaf8d9b10>
[4]            5        [6]        <lasagne.layers.noise.DropoutLayer object at 0x2b7f61d86390> 
[5]            6        [21]       <lasagne.layers.dense.DenseLayer object at 0x2b7f61d863d0>   
[]             7        [8]        <lasagne.layers.input.InputLayer object at 0x2b7eaf8bb550>   
[7]            8        [9]        <lasagne.layers.conv.Conv2DLayer object at 0x2b7eaf8bb650>   
[8]            9        [10]       <lasagne.layers.pool.MaxPool2DLayer object at 0x2b7eaf8d9850>
[9]            10       [11]       <lasagne.layers.conv.Conv2DLayer object at 0x2b7eaf8d9b50>   
[10]           11       [12]       <lasagne.layers.pool.MaxPool2DLayer object at 0x2b7f61d860d0>
[11]           12       [13]       <lasagne.layers.noise.DropoutLayer object at 0x2b7f61d86410> 
[12]           13       [21]       <lasagne.layers.dense.DenseLayer object at 0x2b7f61d86a90>   
[]             14       [15]       <lasagne.layers.input.InputLayer object at 0x2b7eaf8bb590>   
[14]           15       [16]       <lasagne.layers.conv.Conv2DLayer object at 0x2b7eaf8d95d0>   
[15]           16       [17]       <lasagne.layers.pool.MaxPool2DLayer object at 0x2b7eaf8d9ad0>
[16]           17       [18]       <lasagne.layers.conv.Conv2DLayer object at 0x2b7eaf8d9e10>   
[17]           18       [19]       <lasagne.layers.pool.MaxPool2DLayer object at 0x2b7f61d86350>
[18]           19       [20]       <lasagne.layers.noise.DropoutLayer object at 0x2b7f61d86a10> 
[19]           20       [21]       <lasagne.layers.dense.DenseLayer object at 0x2b7f61d86d90>   
[6, 13, 20]    21       [22]       <lasagne.layers.merge.ConcatLayer object at 0x2b7f61d86d10>  
[21]           22       [23]       <lasagne.layers.noise.DropoutLayer object at 0x2b7f61d95050> 
[22]           23       []         <lasagne.layers.dense.DenseLayer object at 0x2b7f61d950d0>   

    ////
    Use AdaGrad update schedule for learning rate, see Duchi, Hazan, and
    Singer (2011) "Adaptive subgradient methods for online learning and
    stochasitic optimization." JMLR, 12:2121-2159
    ////
    

    ////
    Apply Nesterov momentum using Lisa Lab's modifications. 
    ////
    
Starting training...
Epoch 1 of 2 took 133.852s
  training loss:		1.319606
  validation loss:		0.744786
  validation accuracy:		76.23 %
Epoch 2 of 2 took 134.219s
  training loss:		0.821279
  validation loss:		0.675299
  validation accuracy:		78.05 %
Final results:
  test loss:			0.675204
  test accuracy:		77.79 %
Using gpu device 0: Tesla K20m (CNMeM is disabled)
/usr/local/python2/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.
  warnings.warn("downsample module has been moved to the pool module.")
Starting...
 Begin with saved parameters? False
 Saved parameters file: ./lminervatriamese_model1455817051.npz
 Saved parameters file exists? True
 Dataset: /phihome/perdue/theano/data/skim_data_convnet_small.hdf5
 Dataset size: 120041441
 Planned number of epochs: 2
 Learning rate: 0.01
 Momentum: 0.9
 L2 regularization penalty scale: 0.0
Loading data for prediction...
Learning data size: (79775, 3, 50, 50)
Final results:
  test loss:			0.675204
  test accuracy:		77.79 %
   target 1 accuracy:			75.223 %
   target 2 accuracy:			79.581 %
   target 3 accuracy:			79.765 %
   target 4 accuracy:			61.759 %
   target 5 accuracy:			74.254 %
PBS epilogue
