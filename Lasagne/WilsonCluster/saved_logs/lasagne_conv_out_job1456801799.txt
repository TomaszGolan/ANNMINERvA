PBS prologue
Job mnv-conv-1456801799 submitted from mic.fnal.gov started Mon Feb 29 21:10:00 CST 2016 jobid 106284.tev.fnal.gov
gpu1
PBS_O_WORKDIR is /home/perdue/ANNMINERvA/WilsonCluster
Git repo version is 9fa9b881578e-dirty
Git repo contains uncomitted changes! Please commit your changes
before submitting a job. If you feel your changes are experimental,
just use a feature branch.

Changed files:
Lasagne/minerva_ann_operate_networks.py
WilsonCluster/job_lasagne_conv_mlp.sh

Using gpu device 0: Tesla K20m (CNMeM is disabled)
/usr/local/python2/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.
  warnings.warn("downsample module has been moved to the pool module.")
Starting...
minerva_triamese_lasagnefuel.py
 Begin with saved parameters? False
 Saved parameters file: ./lminervatriamese_model1456801800.npz
 Saved parameters file exists? False
 Dataset: /phihome/perdue/theano/data/nukecc_fuel_me1B.hdf5
 Dataset size: 1375177720
 Planned number of epochs: 20
 Learning rate: 0.001
 Momentum: 0.9
 L2 regularization penalty scale: 0.0001
 Batch size: 500
Loading data...
 Learning sample size = 943444 examples
 Validation sample size = 117930 examples
Convpool1 params: {'filter_size': (3, 3), 'pool_size': (2, 2), 'nfilters': 32}
Convpool2 params: {'filter_size': (3, 3), 'pool_size': (2, 2), 'nfilters': 32}

In -->         Layer    --> Out    Description                                                  
-------        -----    -------    -----------                                                  
[]             0        [1]        <lasagne.layers.input.InputLayer object at 0x2b358072f750>   
[0]            1        [2]        <lasagne.layers.conv.Conv2DLayer object at 0x2b358072f850>   
[1]            2        [3]        <lasagne.layers.pool.MaxPool2DLayer object at 0x2b358072f810>
[2]            3        [4]        <lasagne.layers.conv.Conv2DLayer object at 0x2b355cc23850>   
[3]            4        [5]        <lasagne.layers.pool.MaxPool2DLayer object at 0x2b358072f890>
[4]            5        [6]        <lasagne.layers.noise.DropoutLayer object at 0x2b355cc23810> 
[5]            6        [21]       <lasagne.layers.dense.DenseLayer object at 0x2b355cc23ad0>   
[]             7        [8]        <lasagne.layers.input.InputLayer object at 0x2b358072f790>   
[7]            8        [9]        <lasagne.layers.conv.Conv2DLayer object at 0x2b355cc341d0>   
[8]            9        [10]       <lasagne.layers.pool.MaxPool2DLayer object at 0x2b355cc23b50>
[9]            10       [11]       <lasagne.layers.conv.Conv2DLayer object at 0x2b355cc34490>   
[10]           11       [12]       <lasagne.layers.pool.MaxPool2DLayer object at 0x2b355cc34190>
[11]           12       [13]       <lasagne.layers.noise.DropoutLayer object at 0x2b355cc34450> 
[12]           13       [21]       <lasagne.layers.dense.DenseLayer object at 0x2b355cc34710>   
[]             14       [15]       <lasagne.layers.input.InputLayer object at 0x2b358072f7d0>   
[14]           15       [16]       <lasagne.layers.conv.Conv2DLayer object at 0x2b355cc34a50>   
[15]           16       [17]       <lasagne.layers.pool.MaxPool2DLayer object at 0x2b355cc34790>
[16]           17       [18]       <lasagne.layers.conv.Conv2DLayer object at 0x2b355cc34d10>   
[17]           18       [19]       <lasagne.layers.pool.MaxPool2DLayer object at 0x2b355cc34a10>
[18]           19       [20]       <lasagne.layers.noise.DropoutLayer object at 0x2b355cc34cd0> 
[19]           20       [21]       <lasagne.layers.dense.DenseLayer object at 0x2b355cc34f90>   
[6, 13, 20]    21       [22]       <lasagne.layers.merge.ConcatLayer object at 0x2b355cc34f50>  
[21]           22       [23]       <lasagne.layers.noise.DropoutLayer object at 0x2b355cc41310> 
[22]           23       []         <lasagne.layers.dense.DenseLayer object at 0x2b355cc41350>   

        ////
        Use AdaGrad update schedule for learning rate, see Duchi, Hazan, and
        Singer (2011) "Adaptive subgradient methods for online learning and
        stochasitic optimization." JMLR, 12:2121-2159
        ////
        

        ////
        Apply Nesterov momentum using Lisa Lab's modifications.
        ////
        
Starting training...
[(0, 50000), (50000, 100000), (100000, 150000), (150000, 200000), (200000, 250000), (250000, 300000), (300000, 350000), (350000, 400000), (400000, 450000), (450000, 500000), (500000, 550000), (550000, 600000), (600000, 650000), (650000, 700000), (700000, 750000), (750000, 800000), (800000, 850000), (850000, 900000), (900000, 943444)]
(0, 50000)
(50000, 100000)
(100000, 150000)
(150000, 200000)
(200000, 250000)
(250000, 300000)
(300000, 350000)
(350000, 400000)
(400000, 450000)
(450000, 500000)
(500000, 550000)
(550000, 600000)
(600000, 650000)
(650000, 700000)
(700000, 750000)
(750000, 800000)
(800000, 850000)
(850000, 900000)
(900000, 943444)
Epoch 1 of 20 took 169.868s
  training loss:		0.827252
  validation loss:		0.778699
  validation accuracy:		76.85 %
(0, 50000)
(50000, 100000)
(100000, 150000)
(150000, 200000)
(200000, 250000)
(250000, 300000)
(300000, 350000)
(350000, 400000)
(400000, 450000)
(450000, 500000)
(500000, 550000)
(550000, 600000)
(600000, 650000)
(650000, 700000)
(700000, 750000)
(750000, 800000)
(800000, 850000)
(850000, 900000)
(900000, 943444)
Epoch 2 of 20 took 169.926s
  training loss:		0.773396
  validation loss:		0.731998
  validation accuracy:		78.05 %
(0, 50000)
(50000, 100000)
(100000, 150000)
(150000, 200000)
(200000, 250000)
(250000, 300000)
(300000, 350000)
(350000, 400000)
(400000, 450000)
(450000, 500000)
(500000, 550000)
(550000, 600000)
(600000, 650000)
(650000, 700000)
(700000, 750000)
(750000, 800000)
(800000, 850000)
(850000, 900000)
(900000, 943444)
Epoch 3 of 20 took 169.959s
  training loss:		0.749541
  validation loss:		0.710983
  validation accuracy:		78.43 %
(0, 50000)
(50000, 100000)
(100000, 150000)
(150000, 200000)
(200000, 250000)
(250000, 300000)
(300000, 350000)
(350000, 400000)
(400000, 450000)
(450000, 500000)
(500000, 550000)
(550000, 600000)
(600000, 650000)
(650000, 700000)
(700000, 750000)
(750000, 800000)
(800000, 850000)
(850000, 900000)
(900000, 943444)
Epoch 4 of 20 took 170.048s
  training loss:		0.738032
  validation loss:		0.699953
  validation accuracy:		78.73 %
(0, 50000)
(50000, 100000)
(100000, 150000)
(150000, 200000)
(200000, 250000)
(250000, 300000)
(300000, 350000)
(350000, 400000)
(400000, 450000)
(450000, 500000)
(500000, 550000)
(550000, 600000)
(600000, 650000)
(650000, 700000)
(700000, 750000)
(750000, 800000)
(800000, 850000)
(850000, 900000)
(900000, 943444)
Epoch 5 of 20 took 170.166s
  training loss:		0.727922
  validation loss:		0.692045
  validation accuracy:		79.04 %
(0, 50000)
(50000, 100000)
(100000, 150000)
(150000, 200000)
(200000, 250000)
(250000, 300000)
(300000, 350000)
(350000, 400000)
(400000, 450000)
(450000, 500000)
(500000, 550000)
(550000, 600000)
(600000, 650000)
(650000, 700000)
(700000, 750000)
(750000, 800000)
(800000, 850000)
(850000, 900000)
(900000, 943444)
Epoch 6 of 20 took 169.993s
  training loss:		0.722400
  validation loss:		0.686200
  validation accuracy:		79.21 %
(0, 50000)
(50000, 100000)
(100000, 150000)
(150000, 200000)
(200000, 250000)
(250000, 300000)
(300000, 350000)
(350000, 400000)
(400000, 450000)
(450000, 500000)
(500000, 550000)
(550000, 600000)
(600000, 650000)
(650000, 700000)
(700000, 750000)
(750000, 800000)
(800000, 850000)
(850000, 900000)
(900000, 943444)
Epoch 7 of 20 took 170.016s
  training loss:		0.718229
  validation loss:		0.682417
  validation accuracy:		79.27 %
(0, 50000)
(50000, 100000)
(100000, 150000)
(150000, 200000)
(200000, 250000)
(250000, 300000)
(300000, 350000)
(350000, 400000)
(400000, 450000)
(450000, 500000)
(500000, 550000)
(550000, 600000)
(600000, 650000)
(650000, 700000)
(700000, 750000)
(750000, 800000)
(800000, 850000)
(850000, 900000)
(900000, 943444)
Epoch 8 of 20 took 170.088s
  training loss:		0.712599
  validation loss:		0.678215
  validation accuracy:		79.50 %
(0, 50000)
(50000, 100000)
(100000, 150000)
(150000, 200000)
(200000, 250000)
(250000, 300000)
(300000, 350000)
(350000, 400000)
(400000, 450000)
(450000, 500000)
(500000, 550000)
(550000, 600000)
(600000, 650000)
(650000, 700000)
(700000, 750000)
(750000, 800000)
(800000, 850000)
(850000, 900000)
(900000, 943444)
Epoch 9 of 20 took 170.450s
  training loss:		0.711051
  validation loss:		0.675820
  validation accuracy:		79.58 %
(0, 50000)
(50000, 100000)
(100000, 150000)
(150000, 200000)
(200000, 250000)
(250000, 300000)
(300000, 350000)
(350000, 400000)
(400000, 450000)
(450000, 500000)
(500000, 550000)
(550000, 600000)
(600000, 650000)
(650000, 700000)
(700000, 750000)
(750000, 800000)
(800000, 850000)
(850000, 900000)
(900000, 943444)
Epoch 10 of 20 took 170.230s
  training loss:		0.705905
  validation loss:		0.673605
  validation accuracy:		79.64 %
(0, 50000)
(50000, 100000)
(100000, 150000)
(150000, 200000)
(200000, 250000)
(250000, 300000)
(300000, 350000)
(350000, 400000)
(400000, 450000)
(450000, 500000)
(500000, 550000)
(550000, 600000)
(600000, 650000)
(650000, 700000)
(700000, 750000)
(750000, 800000)
(800000, 850000)
(850000, 900000)
(900000, 943444)
Epoch 11 of 20 took 169.909s
  training loss:		0.704834
  validation loss:		0.671547
  validation accuracy:		79.73 %
(0, 50000)
(50000, 100000)
(100000, 150000)
(150000, 200000)
(200000, 250000)
(250000, 300000)
(300000, 350000)
(350000, 400000)
(400000, 450000)
(450000, 500000)
(500000, 550000)
(550000, 600000)
(600000, 650000)
(650000, 700000)
(700000, 750000)
(750000, 800000)
(800000, 850000)
(850000, 900000)
(900000, 943444)
Epoch 12 of 20 took 170.412s
  training loss:		0.699236
  validation loss:		0.669992
  validation accuracy:		79.73 %
(0, 50000)
(50000, 100000)
(100000, 150000)
(150000, 200000)
(200000, 250000)
(250000, 300000)
(300000, 350000)
(350000, 400000)
(400000, 450000)
(450000, 500000)
(500000, 550000)
(550000, 600000)
(600000, 650000)
(650000, 700000)
(700000, 750000)
(750000, 800000)
(800000, 850000)
(850000, 900000)
(900000, 943444)
Epoch 13 of 20 took 169.903s
  training loss:		0.698915
  validation loss:		0.668077
  validation accuracy:		79.82 %
(0, 50000)
(50000, 100000)
(100000, 150000)
(150000, 200000)
(200000, 250000)
(250000, 300000)
(300000, 350000)
(350000, 400000)
(400000, 450000)
(450000, 500000)
(500000, 550000)
(550000, 600000)
(600000, 650000)
(650000, 700000)
(700000, 750000)
(750000, 800000)
(800000, 850000)
(850000, 900000)
(900000, 943444)
Epoch 14 of 20 took 169.877s
  training loss:		0.697503
  validation loss:		0.666882
  validation accuracy:		79.96 %
(0, 50000)
(50000, 100000)
(100000, 150000)
(150000, 200000)
(200000, 250000)
(250000, 300000)
(300000, 350000)
(350000, 400000)
(400000, 450000)
(450000, 500000)
(500000, 550000)
(550000, 600000)
(600000, 650000)
(650000, 700000)
(700000, 750000)
(750000, 800000)
(800000, 850000)
(850000, 900000)
(900000, 943444)
Epoch 15 of 20 took 170.072s
  training loss:		0.695485
  validation loss:		0.665356
  validation accuracy:		79.90 %
(0, 50000)
(50000, 100000)
(100000, 150000)
(150000, 200000)
(200000, 250000)
(250000, 300000)
(300000, 350000)
(350000, 400000)
(400000, 450000)
(450000, 500000)
(500000, 550000)
(550000, 600000)
(600000, 650000)
(650000, 700000)
(700000, 750000)
(750000, 800000)
(800000, 850000)
(850000, 900000)
(900000, 943444)
Epoch 16 of 20 took 169.899s
  training loss:		0.695131
  validation loss:		0.663965
  validation accuracy:		80.03 %
(0, 50000)
(50000, 100000)
(100000, 150000)
(150000, 200000)
(200000, 250000)
(250000, 300000)
(300000, 350000)
(350000, 400000)
(400000, 450000)
(450000, 500000)
(500000, 550000)
(550000, 600000)
(600000, 650000)
(650000, 700000)
(700000, 750000)
(750000, 800000)
(800000, 850000)
(850000, 900000)
(900000, 943444)
Epoch 17 of 20 took 169.872s
  training loss:		0.693556
  validation loss:		0.663526
  validation accuracy:		80.03 %
(0, 50000)
(50000, 100000)
(100000, 150000)
(150000, 200000)
(200000, 250000)
(250000, 300000)
(300000, 350000)
(350000, 400000)
(400000, 450000)
(450000, 500000)
(500000, 550000)
(550000, 600000)
(600000, 650000)
(650000, 700000)
(700000, 750000)
(750000, 800000)
(800000, 850000)
(850000, 900000)
(900000, 943444)
Epoch 18 of 20 took 170.049s
  training loss:		0.693637
  validation loss:		0.662474
  validation accuracy:		80.09 %
(0, 50000)
(50000, 100000)
(100000, 150000)
(150000, 200000)
(200000, 250000)
(250000, 300000)
(300000, 350000)
(350000, 400000)
(400000, 450000)
(450000, 500000)
(500000, 550000)
(550000, 600000)
(600000, 650000)
(650000, 700000)
(700000, 750000)
(750000, 800000)
(800000, 850000)
(850000, 900000)
(900000, 943444)
Epoch 19 of 20 took 169.943s
  training loss:		0.691010
  validation loss:		0.661231
  validation accuracy:		80.13 %
(0, 50000)
(50000, 100000)
(100000, 150000)
(150000, 200000)
(200000, 250000)
(250000, 300000)
(300000, 350000)
(350000, 400000)
(400000, 450000)
(450000, 500000)
(500000, 550000)
(550000, 600000)
(600000, 650000)
(650000, 700000)
(700000, 750000)
(750000, 800000)
(800000, 850000)
(850000, 900000)
(900000, 943444)
Epoch 20 of 20 took 170.768s
  training loss:		0.690940
  validation loss:		0.660540
  validation accuracy:		80.19 %
Finished 20 epochs.
PBS epilogue
