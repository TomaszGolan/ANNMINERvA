PBS prologue
Job lasagne-conv-mnv submitted from mic.fnal.gov started Thu Feb 11 15:57:04 CST 2016 jobid 104565.tev.fnal.gov
gpu1
PBS_O_WORKDIR is /home/perdue/ANNMINERvA/WilsonCluster
Git repo version is 10dd99a9478a
Using gpu device 0: Tesla K20m (CNMeM is disabled)
/usr/local/python2/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.
  warnings.warn("downsample module has been moved to the pool module.")
Starting...
 Begin with saved parameters? False
 Saved parameters file: ./lminervatriamese_model.npz
 Saved parameters file exists? True
 Dataset: /phihome/perdue/theano/data/skim_data_convnet.hdf5
 Dataset size: 225582198
 Planned number of epochs: 200
 Learning rate: 0.001
 Momentum: 0.9
Loading data...
Starting training...
Epoch 1 of 200 took 220.554s
  training loss:		2.261762
  validation loss:		2.207486
  validation accuracy:		21.74 %
Epoch 2 of 200 took 220.454s
  training loss:		2.228754
  validation loss:		2.193330
  validation accuracy:		21.74 %
Epoch 3 of 200 took 220.400s
  training loss:		2.206678
  validation loss:		2.161339
  validation accuracy:		21.90 %
Epoch 4 of 200 took 220.790s
  training loss:		2.152642
  validation loss:		2.047323
  validation accuracy:		34.78 %
Epoch 5 of 200 took 221.142s
  training loss:		1.976051
  validation loss:		1.743252
  validation accuracy:		42.01 %
Epoch 6 of 200 took 221.064s
  training loss:		1.726320
  validation loss:		1.503201
  validation accuracy:		47.41 %
Epoch 7 of 200 took 220.583s
  training loss:		1.586175
  validation loss:		1.405435
  validation accuracy:		49.91 %
Epoch 8 of 200 took 220.681s
  training loss:		1.513863
  validation loss:		1.354526
  validation accuracy:		51.48 %
Epoch 9 of 200 took 220.955s
  training loss:		1.466157
  validation loss:		1.316268
  validation accuracy:		52.86 %
Epoch 10 of 200 took 220.393s
  training loss:		1.435393
  validation loss:		1.287582
  validation accuracy:		53.85 %
Epoch 11 of 200 took 220.594s
  training loss:		1.404481
  validation loss:		1.264780
  validation accuracy:		54.59 %
Epoch 12 of 200 took 220.707s
  training loss:		1.379211
  validation loss:		1.243640
  validation accuracy:		55.06 %
Epoch 13 of 200 took 220.364s
  training loss:		1.360510
  validation loss:		1.235842
  validation accuracy:		55.52 %
Epoch 14 of 200 took 220.437s
  training loss:		1.343986
  validation loss:		1.208854
  validation accuracy:		56.11 %
Epoch 15 of 200 took 221.135s
  training loss:		1.324822
  validation loss:		1.199529
  validation accuracy:		56.69 %
Epoch 16 of 200 took 221.827s
  training loss:		1.310659
  validation loss:		1.184329
  validation accuracy:		57.03 %
Epoch 17 of 200 took 220.647s
  training loss:		1.294864
  validation loss:		1.168718
  validation accuracy:		57.47 %
Epoch 18 of 200 took 220.924s
  training loss:		1.280920
  validation loss:		1.158137
  validation accuracy:		58.15 %
Epoch 19 of 200 took 220.502s
  training loss:		1.268552
  validation loss:		1.148649
  validation accuracy:		58.41 %
Epoch 20 of 200 took 220.414s
  training loss:		1.257148
  validation loss:		1.136470
  validation accuracy:		58.95 %
Epoch 21 of 200 took 220.448s
  training loss:		1.247343
  validation loss:		1.128395
  validation accuracy:		59.26 %
Epoch 22 of 200 took 220.943s
  training loss:		1.236333
  validation loss:		1.116451
  validation accuracy:		59.48 %
Epoch 23 of 200 took 221.171s
  training loss:		1.225743
  validation loss:		1.107813
  validation accuracy:		60.15 %
Epoch 24 of 200 took 221.674s
  training loss:		1.215370
  validation loss:		1.098828
  validation accuracy:		60.47 %
Epoch 25 of 200 took 220.741s
  training loss:		1.207215
  validation loss:		1.091173
  validation accuracy:		60.85 %
Epoch 26 of 200 took 221.146s
  training loss:		1.196482
  validation loss:		1.081730
  validation accuracy:		61.14 %
Epoch 27 of 200 took 220.423s
  training loss:		1.188189
  validation loss:		1.072406
  validation accuracy:		61.59 %
Epoch 28 of 200 took 220.463s
  training loss:		1.180040
  validation loss:		1.066020
  validation accuracy:		61.89 %
Epoch 29 of 200 took 220.483s
  training loss:		1.171229
  validation loss:		1.058177
  validation accuracy:		62.26 %
Epoch 30 of 200 took 220.453s
  training loss:		1.162667
  validation loss:		1.049721
  validation accuracy:		62.71 %
Epoch 31 of 200 took 220.545s
  training loss:		1.155393
  validation loss:		1.044182
  validation accuracy:		62.90 %
Epoch 32 of 200 took 220.408s
  training loss:		1.146392
  validation loss:		1.042710
  validation accuracy:		63.23 %
Epoch 33 of 200 took 220.605s
  training loss:		1.138707
  validation loss:		1.030404
  validation accuracy:		63.53 %
Epoch 34 of 200 took 220.495s
  training loss:		1.131145
  validation loss:		1.022051
  validation accuracy:		64.01 %
Epoch 35 of 200 took 220.468s
  training loss:		1.125451
  validation loss:		1.015467
  validation accuracy:		64.29 %
Epoch 36 of 200 took 220.578s
  training loss:		1.118543
  validation loss:		1.007027
  validation accuracy:		64.55 %
Epoch 37 of 200 took 220.475s
  training loss:		1.111874
  validation loss:		1.002043
  validation accuracy:		64.91 %
Epoch 38 of 200 took 220.547s
  training loss:		1.104698
  validation loss:		0.997034
  validation accuracy:		65.11 %
Epoch 39 of 200 took 220.692s
  training loss:		1.098505
  validation loss:		0.994683
  validation accuracy:		65.48 %
Epoch 40 of 200 took 220.477s
  training loss:		1.093537
  validation loss:		0.983383
  validation accuracy:		65.86 %
Epoch 41 of 200 took 220.497s
  training loss:		1.086951
  validation loss:		0.979516
  validation accuracy:		66.02 %
Epoch 42 of 200 took 220.420s
  training loss:		1.080555
  validation loss:		0.970665
  validation accuracy:		66.20 %
Epoch 43 of 200 took 220.501s
  training loss:		1.075260
  validation loss:		0.966848
  validation accuracy:		66.67 %
Epoch 44 of 200 took 220.451s
  training loss:		1.069981
  validation loss:		0.964546
  validation accuracy:		66.68 %
Epoch 45 of 200 took 220.549s
  training loss:		1.065874
  validation loss:		0.961733
  validation accuracy:		66.88 %
Epoch 46 of 200 took 220.431s
  training loss:		1.057872
  validation loss:		0.955053
  validation accuracy:		67.24 %
Epoch 47 of 200 took 220.453s
  training loss:		1.052837
  validation loss:		0.951244
  validation accuracy:		67.43 %
Epoch 48 of 200 took 220.487s
  training loss:		1.049348
  validation loss:		0.947072
  validation accuracy:		67.82 %
Epoch 49 of 200 took 220.817s
  training loss:		1.043693
  validation loss:		0.938667
  validation accuracy:		67.91 %
Epoch 50 of 200 took 220.460s
  training loss:		1.038971
  validation loss:		0.934822
  validation accuracy:		68.32 %
Epoch 51 of 200 took 220.492s
  training loss:		1.035060
  validation loss:		0.929905
  validation accuracy:		68.46 %
Epoch 52 of 200 took 220.695s
  training loss:		1.028739
  validation loss:		0.927708
  validation accuracy:		68.52 %
Epoch 53 of 200 took 220.442s
  training loss:		1.024217
  validation loss:		0.921375
  validation accuracy:		68.81 %
Epoch 54 of 200 took 220.489s
  training loss:		1.020734
  validation loss:		0.917615
  validation accuracy:		69.08 %
Epoch 55 of 200 took 220.428s
  training loss:		1.015558
  validation loss:		0.911977
  validation accuracy:		69.25 %
Epoch 56 of 200 took 220.393s
  training loss:		1.009535
  validation loss:		0.909096
  validation accuracy:		69.54 %
Epoch 57 of 200 took 220.638s
  training loss:		1.006699
  validation loss:		0.905256
  validation accuracy:		69.73 %
Epoch 58 of 200 took 220.521s
  training loss:		1.001247
  validation loss:		0.900975
  validation accuracy:		69.88 %
Epoch 59 of 200 took 220.679s
  training loss:		0.997710
  validation loss:		0.896529
  validation accuracy:		70.18 %
Epoch 60 of 200 took 220.494s
  training loss:		0.994276
  validation loss:		0.892491
  validation accuracy:		70.31 %
Epoch 61 of 200 took 220.728s
  training loss:		0.989673
  validation loss:		0.888564
  validation accuracy:		70.43 %
Epoch 62 of 200 took 220.520s
  training loss:		0.982967
  validation loss:		0.885093
  validation accuracy:		70.73 %
Epoch 63 of 200 took 220.540s
  training loss:		0.980308
  validation loss:		0.881355
  validation accuracy:		71.06 %
Epoch 64 of 200 took 220.601s
  training loss:		0.975489
  validation loss:		0.877289
  validation accuracy:		71.05 %
Epoch 65 of 200 took 220.426s
  training loss:		0.970756
  validation loss:		0.870336
  validation accuracy:		71.17 %
Epoch 66 of 200 took 220.630s
  training loss:		0.968126
  validation loss:		0.870609
  validation accuracy:		71.31 %
Epoch 67 of 200 took 220.530s
  training loss:		0.962160
  validation loss:		0.867130
  validation accuracy:		71.63 %
Epoch 68 of 200 took 220.435s
  training loss:		0.959843
  validation loss:		0.862453
  validation accuracy:		71.70 %
Epoch 69 of 200 took 220.532s
  training loss:		0.956300
  validation loss:		0.860884
  validation accuracy:		71.87 %
Epoch 70 of 200 took 220.541s
  training loss:		0.950772
  validation loss:		0.858423
  validation accuracy:		71.98 %
Epoch 71 of 200 took 220.560s
  training loss:		0.946271
  validation loss:		0.854398
  validation accuracy:		72.07 %
Epoch 72 of 200 took 220.682s
  training loss:		0.942915
  validation loss:		0.857826
  validation accuracy:		72.32 %
Epoch 73 of 200 took 220.527s
  training loss:		0.941309
  validation loss:		0.848290
  validation accuracy:		72.42 %
Epoch 74 of 200 took 220.483s
  training loss:		0.935858
  validation loss:		0.844371
  validation accuracy:		72.51 %
Epoch 75 of 200 took 220.479s
  training loss:		0.933402
  validation loss:		0.840245
  validation accuracy:		72.51 %
Epoch 76 of 200 took 220.593s
  training loss:		0.930050
  validation loss:		0.838344
  validation accuracy:		72.61 %
Epoch 77 of 200 took 220.527s
  training loss:		0.927504
  validation loss:		0.836572
  validation accuracy:		72.82 %
Epoch 78 of 200 took 220.637s
  training loss:		0.922699
  validation loss:		0.832245
  validation accuracy:		72.92 %
Epoch 79 of 200 took 221.093s
  training loss:		0.919090
  validation loss:		0.829112
  validation accuracy:		72.85 %
Epoch 80 of 200 took 220.657s
  training loss:		0.918137
  validation loss:		0.826716
  validation accuracy:		73.02 %
Epoch 81 of 200 took 220.574s
  training loss:		0.914430
  validation loss:		0.825082
  validation accuracy:		73.13 %
Epoch 82 of 200 took 220.670s
  training loss:		0.910336
  validation loss:		0.821584
  validation accuracy:		73.16 %
Epoch 83 of 200 took 220.547s
  training loss:		0.905904
  validation loss:		0.821207
  validation accuracy:		73.37 %
Epoch 84 of 200 took 220.532s
  training loss:		0.903352
  validation loss:		0.815131
  validation accuracy:		73.32 %
Epoch 85 of 200 took 220.512s
  training loss:		0.901575
  validation loss:		0.814116
  validation accuracy:		73.31 %
Epoch 86 of 200 took 220.388s
  training loss:		0.897680
  validation loss:		0.811010
  validation accuracy:		73.41 %
Epoch 87 of 200 took 220.561s
  training loss:		0.896259
  validation loss:		0.809086
  validation accuracy:		73.50 %
Epoch 88 of 200 took 220.508s
  training loss:		0.891001
  validation loss:		0.807466
  validation accuracy:		73.71 %
Epoch 89 of 200 took 220.387s
  training loss:		0.889604
  validation loss:		0.802496
  validation accuracy:		73.74 %
Epoch 90 of 200 took 220.533s
  training loss:		0.884227
  validation loss:		0.802210
  validation accuracy:		73.91 %
Epoch 91 of 200 took 220.560s
  training loss:		0.883302
  validation loss:		0.796979
  validation accuracy:		73.91 %
Epoch 92 of 200 took 220.526s
  training loss:		0.879746
  validation loss:		0.796965
  validation accuracy:		73.79 %
Epoch 93 of 200 took 220.578s
  training loss:		0.877871
  validation loss:		0.793996
  validation accuracy:		74.10 %
Epoch 94 of 200 took 220.605s
  training loss:		0.876394
  validation loss:		0.796013
  validation accuracy:		74.23 %
Epoch 95 of 200 took 220.515s
  training loss:		0.871452
  validation loss:		0.789437
  validation accuracy:		74.26 %
Epoch 96 of 200 took 220.572s
  training loss:		0.870977
  validation loss:		0.789677
  validation accuracy:		74.35 %
Epoch 97 of 200 took 220.502s
  training loss:		0.868814
  validation loss:		0.786561
  validation accuracy:		74.22 %
Epoch 98 of 200 took 220.518s
  training loss:		0.866265
  validation loss:		0.784500
  validation accuracy:		74.42 %
Epoch 99 of 200 took 220.535s
  training loss:		0.863280
  validation loss:		0.784199
  validation accuracy:		74.62 %
Epoch 100 of 200 took 220.598s
  training loss:		0.859849
  validation loss:		0.778448
  validation accuracy:		74.55 %
Epoch 101 of 200 took 220.462s
  training loss:		0.858020
  validation loss:		0.778404
  validation accuracy:		74.67 %
Epoch 102 of 200 took 220.864s
  training loss:		0.854165
  validation loss:		0.775211
  validation accuracy:		74.49 %
Epoch 103 of 200 took 221.158s
  training loss:		0.853243
  validation loss:		0.774659
  validation accuracy:		74.88 %
Epoch 104 of 200 took 220.544s
  training loss:		0.852294
  validation loss:		0.779034
  validation accuracy:		74.99 %
Epoch 105 of 200 took 220.519s
  training loss:		0.849384
  validation loss:		0.769803
  validation accuracy:		74.77 %
Epoch 106 of 200 took 220.546s
  training loss:		0.846640
  validation loss:		0.770616
  validation accuracy:		74.89 %
Epoch 107 of 200 took 220.577s
  training loss:		0.843770
  validation loss:		0.765443
  validation accuracy:		74.94 %
Epoch 108 of 200 took 220.526s
  training loss:		0.842862
  validation loss:		0.764640
  validation accuracy:		75.03 %
Epoch 109 of 200 took 220.551s
  training loss:		0.839782
  validation loss:		0.764042
  validation accuracy:		75.14 %
Epoch 110 of 200 took 220.501s
  training loss:		0.838352
  validation loss:		0.764561
  validation accuracy:		75.14 %
Epoch 111 of 200 took 220.517s
  training loss:		0.837418
  validation loss:		0.762513
  validation accuracy:		75.26 %
Epoch 112 of 200 took 220.510s
  training loss:		0.833796
  validation loss:		0.757816
  validation accuracy:		75.20 %
Epoch 113 of 200 took 220.381s
  training loss:		0.832653
  validation loss:		0.757817
  validation accuracy:		75.33 %
Epoch 114 of 200 took 220.723s
  training loss:		0.830162
  validation loss:		0.759097
  validation accuracy:		75.33 %
Epoch 115 of 200 took 221.148s
  training loss:		0.827577
  validation loss:		0.754747
  validation accuracy:		75.42 %
Epoch 116 of 200 took 220.634s
  training loss:		0.826207
  validation loss:		0.753554
  validation accuracy:		75.47 %
Epoch 117 of 200 took 220.540s
  training loss:		0.825638
  validation loss:		0.748896
  validation accuracy:		75.41 %
Epoch 118 of 200 took 220.783s
  training loss:		0.823253
  validation loss:		0.749783
  validation accuracy:		75.63 %
Epoch 119 of 200 took 220.392s
  training loss:		0.823838
  validation loss:		0.745502
  validation accuracy:		75.47 %
Epoch 120 of 200 took 220.432s
  training loss:		0.820010
  validation loss:		0.743990
  validation accuracy:		75.65 %
Epoch 121 of 200 took 220.470s
  training loss:		0.819035
  validation loss:		0.743036
  validation accuracy:		75.58 %
Epoch 122 of 200 took 220.627s
  training loss:		0.817689
  validation loss:		0.741547
  validation accuracy:		75.73 %
Epoch 123 of 200 took 220.630s
  training loss:		0.814880
  validation loss:		0.740781
  validation accuracy:		75.72 %
Epoch 124 of 200 took 220.456s
  training loss:		0.814063
  validation loss:		0.742653
  validation accuracy:		75.65 %
Epoch 125 of 200 took 220.455s
  training loss:		0.812048
  validation loss:		0.740078
  validation accuracy:		75.80 %
Epoch 126 of 200 took 220.386s
  training loss:		0.809418
  validation loss:		0.738586
  validation accuracy:		75.84 %
Epoch 127 of 200 took 220.661s
  training loss:		0.810178
  validation loss:		0.734112
  validation accuracy:		75.78 %
Epoch 128 of 200 took 220.608s
  training loss:		0.808379
  validation loss:		0.735814
  validation accuracy:		76.00 %
Epoch 129 of 200 took 220.486s
  training loss:		0.806012
  validation loss:		0.732144
  validation accuracy:		75.89 %
Epoch 130 of 200 took 220.711s
  training loss:		0.803506
  validation loss:		0.728692
  validation accuracy:		75.91 %
Epoch 131 of 200 took 220.738s
  training loss:		0.802130
  validation loss:		0.730719
  validation accuracy:		75.94 %
Epoch 132 of 200 took 220.441s
  training loss:		0.800824
  validation loss:		0.729880
  validation accuracy:		76.02 %
Epoch 133 of 200 took 220.546s
  training loss:		0.800173
  validation loss:		0.726385
  validation accuracy:		76.06 %
Epoch 134 of 200 took 220.687s
  training loss:		0.798567
  validation loss:		0.727095
  validation accuracy:		76.00 %
Epoch 135 of 200 took 221.648s
  training loss:		0.797355
  validation loss:		0.723834
  validation accuracy:		76.10 %
Epoch 136 of 200 took 220.474s
  training loss:		0.795809
  validation loss:		0.724584
  validation accuracy:		76.16 %
Epoch 137 of 200 took 220.527s
  training loss:		0.794439
  validation loss:		0.724412
  validation accuracy:		76.20 %
Epoch 138 of 200 took 220.607s
  training loss:		0.792372
  validation loss:		0.722820
  validation accuracy:		76.15 %
Epoch 139 of 200 took 220.824s
  training loss:		0.791780
  validation loss:		0.721104
  validation accuracy:		76.22 %
Epoch 140 of 200 took 220.541s
  training loss:		0.791307
  validation loss:		0.719167
  validation accuracy:		76.25 %
Epoch 141 of 200 took 220.502s
  training loss:		0.789616
  validation loss:		0.718033
  validation accuracy:		76.25 %
Epoch 142 of 200 took 221.716s
  training loss:		0.788204
  validation loss:		0.716665
  validation accuracy:		76.33 %
Epoch 143 of 200 took 220.446s
  training loss:		0.788535
  validation loss:		0.717522
  validation accuracy:		76.30 %
Epoch 144 of 200 took 220.703s
  training loss:		0.786266
  validation loss:		0.716821
  validation accuracy:		76.38 %
Epoch 145 of 200 took 220.545s
  training loss:		0.785596
  validation loss:		0.716467
  validation accuracy:		76.29 %
Epoch 146 of 200 took 220.615s
  training loss:		0.783991
  validation loss:		0.712254
  validation accuracy:		76.47 %
Epoch 147 of 200 took 220.408s
  training loss:		0.785262
  validation loss:		0.712761
  validation accuracy:		76.45 %
Epoch 148 of 200 took 220.483s
  training loss:		0.780868
  validation loss:		0.714725
  validation accuracy:		76.46 %
Epoch 149 of 200 took 221.171s
  training loss:		0.781004
  validation loss:		0.710621
  validation accuracy:		76.43 %
Epoch 150 of 200 took 220.626s
  training loss:		0.779319
  validation loss:		0.709217
  validation accuracy:		76.51 %
Epoch 151 of 200 took 220.584s
  training loss:		0.777354
  validation loss:		0.708688
  validation accuracy:		76.49 %
Epoch 152 of 200 took 220.505s
  training loss:		0.777341
  validation loss:		0.708903
  validation accuracy:		76.56 %
Epoch 153 of 200 took 220.451s
  training loss:		0.775627
  validation loss:		0.709190
  validation accuracy:		76.54 %
Epoch 154 of 200 took 220.517s
  training loss:		0.773711
  validation loss:		0.705014
  validation accuracy:		76.51 %
Epoch 155 of 200 took 220.567s
  training loss:		0.773853
  validation loss:		0.703476
  validation accuracy:		76.60 %
Epoch 156 of 200 took 220.381s
  training loss:		0.771812
  validation loss:		0.704977
  validation accuracy:		76.65 %
Epoch 157 of 200 took 220.866s
  training loss:		0.771102
  validation loss:		0.705462
  validation accuracy:		76.60 %
Epoch 158 of 200 took 220.599s
  training loss:		0.770734
  validation loss:		0.702908
  validation accuracy:		76.74 %
Epoch 159 of 200 took 220.751s
  training loss:		0.769625
  validation loss:		0.700046
  validation accuracy:		76.78 %
Epoch 160 of 200 took 220.455s
  training loss:		0.766618
  validation loss:		0.700926
  validation accuracy:		76.70 %
Epoch 161 of 200 took 220.895s
  training loss:		0.765306
  validation loss:		0.698494
  validation accuracy:		76.78 %
Epoch 162 of 200 took 220.707s
  training loss:		0.765701
  validation loss:		0.697168
  validation accuracy:		76.77 %
Epoch 163 of 200 took 221.226s
  training loss:		0.765618
  validation loss:		0.701651
  validation accuracy:		76.88 %
Epoch 164 of 200 took 221.499s
  training loss:		0.764173
  validation loss:		0.699594
  validation accuracy:		76.81 %
Epoch 165 of 200 took 220.428s
  training loss:		0.762787
  validation loss:		0.695046
  validation accuracy:		76.77 %
Epoch 166 of 200 took 220.568s
  training loss:		0.761154
  validation loss:		0.694885
  validation accuracy:		76.88 %
Epoch 167 of 200 took 221.014s
  training loss:		0.759797
  validation loss:		0.694806
  validation accuracy:		76.90 %
Epoch 168 of 200 took 220.682s
  training loss:		0.758618
  validation loss:		0.694135
  validation accuracy:		76.91 %
Epoch 169 of 200 took 220.449s
  training loss:		0.758890
  validation loss:		0.692024
  validation accuracy:		76.78 %
Epoch 170 of 200 took 220.436s
  training loss:		0.757352
  validation loss:		0.694149
  validation accuracy:		77.00 %
Epoch 171 of 200 took 220.517s
  training loss:		0.757423
  validation loss:		0.689193
  validation accuracy:		76.97 %
Epoch 172 of 200 took 220.506s
  training loss:		0.755420
  validation loss:		0.689015
  validation accuracy:		76.89 %
Epoch 173 of 200 took 220.638s
  training loss:		0.754649
  validation loss:		0.689901
  validation accuracy:		76.95 %
Epoch 174 of 200 took 221.193s
  training loss:		0.752555
  validation loss:		0.688074
  validation accuracy:		77.08 %
Epoch 175 of 200 took 220.456s
  training loss:		0.750914
  validation loss:		0.687276
  validation accuracy:		77.03 %
Epoch 176 of 200 took 220.786s
  training loss:		0.751613
  validation loss:		0.685831
  validation accuracy:		77.14 %
Epoch 177 of 200 took 220.829s
  training loss:		0.750048
  validation loss:		0.683378
  validation accuracy:		77.12 %
Epoch 178 of 200 took 220.668s
  training loss:		0.749613
  validation loss:		0.684312
  validation accuracy:		77.10 %
Epoch 179 of 200 took 220.922s
  training loss:		0.748436
  validation loss:		0.683303
  validation accuracy:		77.10 %
Epoch 180 of 200 took 220.706s
  training loss:		0.747303
  validation loss:		0.686502
  validation accuracy:		77.12 %
Epoch 181 of 200 took 220.441s
  training loss:		0.747384
  validation loss:		0.683117
  validation accuracy:		77.17 %
Epoch 182 of 200 took 220.445s
  training loss:		0.745521
  validation loss:		0.682388
  validation accuracy:		77.14 %
Epoch 183 of 200 took 220.538s
  training loss:		0.744867
  validation loss:		0.686048
  validation accuracy:		77.18 %
Epoch 184 of 200 took 220.467s
  training loss:		0.743939
  validation loss:		0.678866
  validation accuracy:		77.17 %
Epoch 185 of 200 took 220.479s
  training loss:		0.743467
  validation loss:		0.680116
  validation accuracy:		77.20 %
Epoch 186 of 200 took 220.530s
  training loss:		0.742192
  validation loss:		0.678219
  validation accuracy:		77.22 %
Epoch 187 of 200 took 220.651s
  training loss:		0.741440
  validation loss:		0.677124
  validation accuracy:		77.17 %
Epoch 188 of 200 took 220.498s
  training loss:		0.741204
  validation loss:		0.679772
  validation accuracy:		77.26 %
Epoch 189 of 200 took 220.523s
  training loss:		0.739291
  validation loss:		0.676652
  validation accuracy:		77.21 %
Epoch 190 of 200 took 220.422s
  training loss:		0.737985
  validation loss:		0.676791
  validation accuracy:		77.28 %
Epoch 191 of 200 took 220.472s
  training loss:		0.738302
  validation loss:		0.675316
  validation accuracy:		77.22 %
Epoch 192 of 200 took 220.941s
  training loss:		0.736423
  validation loss:		0.675587
  validation accuracy:		77.35 %
Epoch 193 of 200 took 220.929s
  training loss:		0.735969
  validation loss:		0.673267
  validation accuracy:		77.35 %
Epoch 194 of 200 took 220.493s
  training loss:		0.736673
  validation loss:		0.672681
  validation accuracy:		77.31 %
Epoch 195 of 200 took 220.442s
  training loss:		0.735227
  validation loss:		0.677324
  validation accuracy:		77.37 %
Epoch 196 of 200 took 220.482s
  training loss:		0.733077
  validation loss:		0.670406
  validation accuracy:		77.44 %
Epoch 197 of 200 took 220.566s
  training loss:		0.733525
  validation loss:		0.670787
  validation accuracy:		77.47 %
Epoch 198 of 200 took 220.411s
  training loss:		0.732450
  validation loss:		0.668365
  validation accuracy:		77.40 %
Epoch 199 of 200 took 221.044s
  training loss:		0.730886
  validation loss:		0.671292
  validation accuracy:		77.28 %
Epoch 200 of 200 took 220.497s
  training loss:		0.732146
  validation loss:		0.668632
  validation accuracy:		77.33 %
Final results:
  test loss:			0.665805
  test accuracy:		77.37 %
PBS epilogue
