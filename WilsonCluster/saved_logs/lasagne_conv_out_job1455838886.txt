PBS prologue
Job lasagne-conv-mnv submitted from mic.fnal.gov started Thu Feb 18 17:41:27 CST 2016 jobid 105134.tev.fnal.gov
gpu1
PBS_O_WORKDIR is /home/perdue/ANNMINERvA/WilsonCluster
Git repo version is a6099dd93142
Using gpu device 0: Tesla K20m (CNMeM is disabled)
/usr/local/python2/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.
  warnings.warn("downsample module has been moved to the pool module.")
Starting...
 Begin with saved parameters? False
 Saved parameters file: ./lminervatriamese_model1455838887.npz
 Saved parameters file exists? False
 Dataset: /phihome/perdue/theano/data/skim_data_convnet.hdf5
 Dataset size: 479032538
 Planned number of epochs: 100
 Learning rate: 0.01
 Momentum: 0.9
 L2 regularization penalty scale: 0.0001
 Batch size: 500
Loading data...
Learning data size: (319073, 3, 50, 50)

In -->         Layer    --> Out    Description                                                  
-------        -----    -------    -----------                                                  
[]             0        [1]        <lasagne.layers.input.InputLayer object at 0x2b9c9d482b50>   
[0]            1        [2]        <lasagne.layers.conv.Conv2DLayer object at 0x2b9c9d482c50>   
[1]            2        [3]        <lasagne.layers.pool.MaxPool2DLayer object at 0x2b9c9d482c10>
[2]            3        [4]        <lasagne.layers.conv.Conv2DLayer object at 0x2b9f66a3b110>   
[3]            4        [5]        <lasagne.layers.pool.MaxPool2DLayer object at 0x2b9f66a3b190>
[4]            5        [6]        <lasagne.layers.noise.DropoutLayer object at 0x2b9f66a3b9d0> 
[5]            6        [21]       <lasagne.layers.dense.DenseLayer object at 0x2b9f66a3ba10>   
[]             7        [8]        <lasagne.layers.input.InputLayer object at 0x2b9c9d482b90>   
[7]            8        [9]        <lasagne.layers.conv.Conv2DLayer object at 0x2b9c9d482c90>   
[8]            9        [10]       <lasagne.layers.pool.MaxPool2DLayer object at 0x2b9c9d49ce90>
[9]            10       [11]       <lasagne.layers.conv.Conv2DLayer object at 0x2b9f66a3b1d0>   
[10]           11       [12]       <lasagne.layers.pool.MaxPool2DLayer object at 0x2b9f66a3b710>
[11]           12       [13]       <lasagne.layers.noise.DropoutLayer object at 0x2b9f66a3ba50> 
[12]           13       [21]       <lasagne.layers.dense.DenseLayer object at 0x2b9f66a49110>   
[]             14       [15]       <lasagne.layers.input.InputLayer object at 0x2b9c9d482bd0>   
[14]           15       [16]       <lasagne.layers.conv.Conv2DLayer object at 0x2b9c9d49cc10>   
[15]           16       [17]       <lasagne.layers.pool.MaxPool2DLayer object at 0x2b9f66a3b150>
[16]           17       [18]       <lasagne.layers.conv.Conv2DLayer object at 0x2b9f66a3b490>   
[17]           18       [19]       <lasagne.layers.pool.MaxPool2DLayer object at 0x2b9f66a3b990>
[18]           19       [20]       <lasagne.layers.noise.DropoutLayer object at 0x2b9f66a49090> 
[19]           20       [21]       <lasagne.layers.dense.DenseLayer object at 0x2b9f66a49410>   
[6, 13, 20]    21       [22]       <lasagne.layers.merge.ConcatLayer object at 0x2b9f66a49390>  
[21]           22       [23]       <lasagne.layers.noise.DropoutLayer object at 0x2b9f66a496d0> 
[22]           23       []         <lasagne.layers.dense.DenseLayer object at 0x2b9f66a49690>   

        ////
        Use AdaGrad update schedule for learning rate, see Duchi, Hazan, and
        Singer (2011) "Adaptive subgradient methods for online learning and
        stochasitic optimization." JMLR, 12:2121-2159
        ////
        

        ////
        Apply Nesterov momentum using Lisa Lab's modifications.
        ////
        
Starting training...
Epoch 1 of 100 took 539.547s
  training loss:		1.309339
  validation loss:		0.844351
  validation accuracy:		77.85 %
Epoch 2 of 100 took 539.689s
  training loss:		0.919902
  validation loss:		0.775596
  validation accuracy:		78.78 %
Epoch 3 of 100 took 539.404s
  training loss:		0.874402
  validation loss:		0.756718
  validation accuracy:		78.92 %
Epoch 4 of 100 took 539.831s
  training loss:		0.855538
  validation loss:		0.740676
  validation accuracy:		79.15 %
Epoch 5 of 100 took 539.846s
  training loss:		0.838407
  validation loss:		0.734033
  validation accuracy:		79.26 %
Epoch 6 of 100 took 539.601s
  training loss:		0.831012
  validation loss:		0.727650
  validation accuracy:		79.40 %
Epoch 7 of 100 took 539.615s
  training loss:		0.822649
  validation loss:		0.723105
  validation accuracy:		79.42 %
Epoch 8 of 100 took 539.914s
  training loss:		0.816192
  validation loss:		0.716344
  validation accuracy:		79.39 %
Epoch 9 of 100 took 539.902s
  training loss:		0.806704
  validation loss:		0.720310
  validation accuracy:		79.68 %
Epoch 10 of 100 took 539.845s
  training loss:		0.816001
  validation loss:		0.708187
  validation accuracy:		79.71 %
Epoch 11 of 100 took 539.842s
  training loss:		0.800841
  validation loss:		0.701943
  validation accuracy:		79.96 %
Epoch 12 of 100 took 539.763s
  training loss:		0.792990
  validation loss:		0.693473
  validation accuracy:		80.08 %
Epoch 13 of 100 took 541.417s
  training loss:		0.789126
  validation loss:		0.689868
  validation accuracy:		80.01 %
Epoch 14 of 100 took 539.892s
  training loss:		0.780842
  validation loss:		0.684501
  validation accuracy:		80.15 %
Epoch 15 of 100 took 539.851s
  training loss:		0.776515
  validation loss:		0.679340
  validation accuracy:		80.35 %
Epoch 16 of 100 took 539.800s
  training loss:		0.769869
  validation loss:		0.676984
  validation accuracy:		80.54 %
Epoch 17 of 100 took 539.843s
  training loss:		0.768335
  validation loss:		0.675637
  validation accuracy:		80.48 %
Epoch 18 of 100 took 539.817s
  training loss:		0.768061
  validation loss:		0.670967
  validation accuracy:		80.62 %
Epoch 19 of 100 took 539.898s
  training loss:		0.762013
  validation loss:		0.669352
  validation accuracy:		80.63 %
Epoch 20 of 100 took 539.947s
  training loss:		0.759643
  validation loss:		0.669008
  validation accuracy:		80.65 %
Epoch 21 of 100 took 539.812s
  training loss:		0.757919
  validation loss:		0.665695
  validation accuracy:		80.75 %
Epoch 22 of 100 took 539.859s
  training loss:		0.756370
  validation loss:		0.668490
  validation accuracy:		80.77 %
Epoch 23 of 100 took 539.860s
  training loss:		0.755058
  validation loss:		0.663163
  validation accuracy:		80.81 %
Epoch 24 of 100 took 540.030s
  training loss:		0.754656
  validation loss:		0.662188
  validation accuracy:		80.81 %
Epoch 25 of 100 took 539.851s
  training loss:		0.753812
  validation loss:		0.663068
  validation accuracy:		80.71 %
Epoch 26 of 100 took 539.876s
  training loss:		0.751785
  validation loss:		0.659969
  validation accuracy:		80.87 %
Epoch 27 of 100 took 539.886s
  training loss:		0.754708
  validation loss:		0.663546
  validation accuracy:		80.76 %
Epoch 28 of 100 took 539.861s
  training loss:		0.752614
  validation loss:		0.658286
  validation accuracy:		80.93 %
Epoch 29 of 100 took 539.835s
  training loss:		0.749370
  validation loss:		0.657864
  validation accuracy:		80.72 %
Epoch 30 of 100 took 539.777s
  training loss:		0.747987
  validation loss:		0.658406
  validation accuracy:		80.82 %
Epoch 31 of 100 took 539.843s
  training loss:		0.746896
  validation loss:		0.655194
  validation accuracy:		81.07 %
Epoch 32 of 100 took 539.861s
  training loss:		0.745654
  validation loss:		0.656840
  validation accuracy:		80.98 %
Epoch 33 of 100 took 539.893s
  training loss:		0.746764
  validation loss:		0.654585
  validation accuracy:		80.96 %
Epoch 34 of 100 took 539.822s
  training loss:		0.746012
  validation loss:		0.657215
  validation accuracy:		80.78 %
Epoch 35 of 100 took 539.796s
  training loss:		0.744545
  validation loss:		0.661458
  validation accuracy:		80.87 %
Epoch 36 of 100 took 539.751s
  training loss:		0.750397
  validation loss:		0.660481
  validation accuracy:		80.74 %
Epoch 37 of 100 took 539.810s
  training loss:		0.744296
  validation loss:		0.655242
  validation accuracy:		80.91 %
Epoch 38 of 100 took 539.887s
  training loss:		0.748834
  validation loss:		0.653218
  validation accuracy:		81.01 %
Epoch 39 of 100 took 539.891s
  training loss:		0.743524
  validation loss:		0.654152
  validation accuracy:		80.96 %
Epoch 40 of 100 took 539.942s
  training loss:		0.747306
  validation loss:		0.653080
  validation accuracy:		80.88 %
Epoch 41 of 100 took 539.836s
  training loss:		0.743797
  validation loss:		0.651725
  validation accuracy:		81.01 %
Epoch 42 of 100 took 539.901s
  training loss:		0.739314
  validation loss:		0.649376
  validation accuracy:		80.97 %
Epoch 43 of 100 took 539.977s
  training loss:		0.739506
  validation loss:		0.649274
  validation accuracy:		80.83 %
Epoch 44 of 100 took 539.884s
  training loss:		0.737606
  validation loss:		0.647493
  validation accuracy:		81.08 %
Epoch 45 of 100 took 539.835s
  training loss:		0.736770
  validation loss:		0.647831
  validation accuracy:		81.00 %
Epoch 46 of 100 took 539.735s
  training loss:		0.735687
  validation loss:		0.647221
  validation accuracy:		81.06 %
Epoch 47 of 100 took 539.819s
  training loss:		0.734208
  validation loss:		0.647936
  validation accuracy:		81.09 %
Epoch 48 of 100 took 539.798s
  training loss:		0.736514
  validation loss:		0.647867
  validation accuracy:		81.04 %
Epoch 49 of 100 took 539.773s
  training loss:		0.736525
  validation loss:		0.650170
  validation accuracy:		80.89 %
Epoch 50 of 100 took 539.842s
  training loss:		0.734587
  validation loss:		0.645391
  validation accuracy:		81.03 %
Epoch 51 of 100 took 539.836s
  training loss:		0.734546
  validation loss:		0.648208
  validation accuracy:		80.99 %
Epoch 52 of 100 took 539.885s
  training loss:		0.732887
  validation loss:		0.645950
  validation accuracy:		81.01 %
Epoch 53 of 100 took 539.861s
  training loss:		0.732590
  validation loss:		0.647414
  validation accuracy:		81.08 %
Epoch 54 of 100 took 539.750s
  training loss:		0.732657
  validation loss:		0.645986
  validation accuracy:		80.89 %
Epoch 55 of 100 took 539.711s
  training loss:		0.734024
  validation loss:		0.648699
  validation accuracy:		80.97 %
Epoch 56 of 100 took 539.834s
  training loss:		0.731225
  validation loss:		0.643918
  validation accuracy:		81.11 %
Epoch 57 of 100 took 539.810s
  training loss:		0.746368
  validation loss:		0.651546
  validation accuracy:		80.84 %
Epoch 58 of 100 took 539.909s
  training loss:		0.745608
  validation loss:		0.651627
  validation accuracy:		80.83 %
Epoch 59 of 100 took 539.827s
  training loss:		0.746858
  validation loss:		0.650484
  validation accuracy:		80.92 %
Epoch 60 of 100 took 539.793s
  training loss:		0.743367
  validation loss:		0.658055
  validation accuracy:		80.69 %
Epoch 61 of 100 took 539.844s
  training loss:		0.743767
  validation loss:		0.652633
  validation accuracy:		80.64 %
Epoch 62 of 100 took 542.010s
  training loss:		0.738485
  validation loss:		0.649575
  validation accuracy:		80.95 %
Epoch 63 of 100 took 540.984s
  training loss:		0.743032
  validation loss:		0.649790
  validation accuracy:		81.01 %
Epoch 64 of 100 took 540.873s
  training loss:		0.737492
  validation loss:		0.648996
  validation accuracy:		80.93 %
Epoch 65 of 100 took 539.882s
  training loss:		0.729833
  validation loss:		0.645175
  validation accuracy:		81.10 %
Epoch 66 of 100 took 539.772s
  training loss:		0.740999
  validation loss:		0.644902
  validation accuracy:		81.06 %
Epoch 67 of 100 took 539.740s
  training loss:		0.733055
  validation loss:		0.645438
  validation accuracy:		81.21 %
Epoch 68 of 100 took 539.834s
  training loss:		0.729467
  validation loss:		0.643241
  validation accuracy:		81.10 %
Epoch 69 of 100 took 539.748s
  training loss:		0.728265
  validation loss:		0.643109
  validation accuracy:		81.08 %
Epoch 70 of 100 took 539.734s
  training loss:		0.728079
  validation loss:		0.650375
  validation accuracy:		80.93 %
Epoch 71 of 100 took 539.819s
  training loss:		0.729084
  validation loss:		0.644332
  validation accuracy:		80.82 %
Epoch 72 of 100 took 539.867s
  training loss:		0.726163
  validation loss:		0.642955
  validation accuracy:		81.09 %
Epoch 73 of 100 took 539.705s
  training loss:		0.724708
  validation loss:		0.642918
  validation accuracy:		81.00 %
Epoch 74 of 100 took 539.671s
  training loss:		0.726624
  validation loss:		0.647962
  validation accuracy:		81.03 %
Epoch 75 of 100 took 539.700s
  training loss:		0.726648
  validation loss:		0.646580
  validation accuracy:		81.01 %
Epoch 76 of 100 took 539.738s
  training loss:		0.740756
  validation loss:		0.657776
  validation accuracy:		80.42 %
Epoch 77 of 100 took 539.789s
  training loss:		0.741228
  validation loss:		0.649608
  validation accuracy:		80.90 %
Epoch 78 of 100 took 540.265s
  training loss:		0.734771
  validation loss:		0.661011
  validation accuracy:		80.37 %
Epoch 79 of 100 took 540.387s
  training loss:		0.742738
  validation loss:		0.644838
  validation accuracy:		81.06 %
Epoch 80 of 100 took 542.293s
  training loss:		0.728062
  validation loss:		0.642550
  validation accuracy:		81.23 %
Epoch 81 of 100 took 541.003s
  training loss:		0.725413
  validation loss:		0.641774
  validation accuracy:		81.11 %
Epoch 82 of 100 took 540.279s
  training loss:		0.723483
  validation loss:		0.641168
  validation accuracy:		81.10 %
Epoch 83 of 100 took 540.116s
  training loss:		0.745807
  validation loss:		0.650367
  validation accuracy:		80.81 %
Epoch 84 of 100 took 539.655s
  training loss:		0.727869
  validation loss:		0.640789
  validation accuracy:		81.05 %
Epoch 85 of 100 took 539.672s
  training loss:		0.723575
  validation loss:		0.641485
  validation accuracy:		81.04 %
Epoch 86 of 100 took 539.876s
  training loss:		0.724544
  validation loss:		0.640605
  validation accuracy:		81.10 %
Epoch 87 of 100 took 539.760s
  training loss:		0.725249
  validation loss:		0.641153
  validation accuracy:		81.05 %
Epoch 88 of 100 took 539.667s
  training loss:		0.724931
  validation loss:		0.648586
  validation accuracy:		80.81 %
Epoch 89 of 100 took 539.752s
  training loss:		0.726778
  validation loss:		0.640896
  validation accuracy:		81.09 %
Epoch 90 of 100 took 539.842s
  training loss:		0.722049
  validation loss:		0.642115
  validation accuracy:		81.05 %
Epoch 91 of 100 took 539.877s
  training loss:		0.723607
  validation loss:		0.640322
  validation accuracy:		81.09 %
Epoch 92 of 100 took 540.693s
  training loss:		0.725182
  validation loss:		0.640909
  validation accuracy:		81.07 %
Epoch 93 of 100 took 540.660s
  training loss:		0.735802
  validation loss:		0.642519
  validation accuracy:		81.10 %
Epoch 94 of 100 took 539.750s
  training loss:		0.728015
  validation loss:		0.640367
  validation accuracy:		81.03 %
Epoch 95 of 100 took 539.825s
  training loss:		0.723224
  validation loss:		0.641599
  validation accuracy:		81.06 %
Epoch 96 of 100 took 540.060s
  training loss:		0.724956
  validation loss:		0.641286
  validation accuracy:		80.99 %
Epoch 97 of 100 took 539.751s
  training loss:		0.722076
  validation loss:		0.638367
  validation accuracy:		81.13 %
Epoch 98 of 100 took 539.902s
  training loss:		0.726845
  validation loss:		0.637967
  validation accuracy:		81.10 %
Epoch 99 of 100 took 539.752s
  training loss:		0.724658
  validation loss:		0.638767
  validation accuracy:		81.14 %
Epoch 100 of 100 took 539.804s
  training loss:		0.720696
  validation loss:		0.636027
  validation accuracy:		81.21 %
Final results:
  test loss:			0.633646
  test accuracy:		81.46 %
Using gpu device 0: Tesla K20m (CNMeM is disabled)
/usr/local/python2/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.
  warnings.warn("downsample module has been moved to the pool module.")
Starting...
 Begin with saved parameters? False
 Saved parameters file: ./lminervatriamese_model1455838887.npz
 Saved parameters file exists? True
 Dataset: /phihome/perdue/theano/data/skim_data_convnet.hdf5
 Dataset size: 479032538
 Planned number of epochs: 100
 Learning rate: 0.01
 Momentum: 0.9
 L2 regularization penalty scale: 0.0001
 Batch size: 500
Loading data for prediction...
Learning data size: (319073, 3, 50, 50)
Final results:
  test loss:			0.548477
  test accuracy:		81.46 %
   target 1 accuracy:			81.629 %
   target 2 accuracy:			85.373 %
   target 3 accuracy:			82.706 %
   target 4 accuracy:			74.389 %
   target 5 accuracy:			77.254 %
PBS epilogue
