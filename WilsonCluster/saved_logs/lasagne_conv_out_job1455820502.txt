PBS prologue
Job lasagne-conv-mnv submitted from mic.fnal.gov started Thu Feb 18 12:35:04 CST 2016 jobid 105130.tev.fnal.gov
gpu1
PBS_O_WORKDIR is /home/perdue/ANNMINERvA/WilsonCluster
Git repo version is 9b14e7872a93
Using gpu device 0: Tesla K20m (CNMeM is disabled)
/usr/local/python2/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.
  warnings.warn("downsample module has been moved to the pool module.")
Starting...
 Begin with saved parameters? False
 Saved parameters file: ./lminervatriamese_model1455820504.npz
 Saved parameters file exists? False
 Dataset: /phihome/perdue/theano/data/skim_data_convnet_small.hdf5
 Dataset size: 120041441
 Planned number of epochs: 100
 Learning rate: 0.01
 Momentum: 0.9
 L2 regularization penalty scale: 0.0001
Loading data...
Learning data size: (79775, 3, 50, 50)

In -->         Layer    --> Out    Description                                                  
-------        -----    -------    -----------                                                  
[]             0        [1]        <lasagne.layers.input.InputLayer object at 0x2afae0c76b50>   
[0]            1        [2]        <lasagne.layers.conv.Conv2DLayer object at 0x2afae0c76c50>   
[1]            2        [3]        <lasagne.layers.pool.MaxPool2DLayer object at 0x2afae0c76c10>
[2]            3        [4]        <lasagne.layers.conv.Conv2DLayer object at 0x2afb9313e110>   
[3]            4        [5]        <lasagne.layers.pool.MaxPool2DLayer object at 0x2afb9313e190>
[4]            5        [6]        <lasagne.layers.noise.DropoutLayer object at 0x2afb9313e9d0> 
[5]            6        [21]       <lasagne.layers.dense.DenseLayer object at 0x2afb9313ea10>   
[]             7        [8]        <lasagne.layers.input.InputLayer object at 0x2afae0c76b90>   
[7]            8        [9]        <lasagne.layers.conv.Conv2DLayer object at 0x2afae0c76c90>   
[8]            9        [10]       <lasagne.layers.pool.MaxPool2DLayer object at 0x2afae0c8fe90>
[9]            10       [11]       <lasagne.layers.conv.Conv2DLayer object at 0x2afb9313e1d0>   
[10]           11       [12]       <lasagne.layers.pool.MaxPool2DLayer object at 0x2afb9313e710>
[11]           12       [13]       <lasagne.layers.noise.DropoutLayer object at 0x2afb9313ea50> 
[12]           13       [21]       <lasagne.layers.dense.DenseLayer object at 0x2afb9314c110>   
[]             14       [15]       <lasagne.layers.input.InputLayer object at 0x2afae0c76bd0>   
[14]           15       [16]       <lasagne.layers.conv.Conv2DLayer object at 0x2afae0c8fc10>   
[15]           16       [17]       <lasagne.layers.pool.MaxPool2DLayer object at 0x2afb9313e150>
[16]           17       [18]       <lasagne.layers.conv.Conv2DLayer object at 0x2afb9313e490>   
[17]           18       [19]       <lasagne.layers.pool.MaxPool2DLayer object at 0x2afb9313e990>
[18]           19       [20]       <lasagne.layers.noise.DropoutLayer object at 0x2afb9314c090> 
[19]           20       [21]       <lasagne.layers.dense.DenseLayer object at 0x2afb9314c410>   
[6, 13, 20]    21       [22]       <lasagne.layers.merge.ConcatLayer object at 0x2afb9314c390>  
[21]           22       [23]       <lasagne.layers.noise.DropoutLayer object at 0x2afb9314c6d0> 
[22]           23       []         <lasagne.layers.dense.DenseLayer object at 0x2afb9314c690>   

        ////
        Use AdaGrad update schedule for learning rate, see Duchi, Hazan, and
        Singer (2011) "Adaptive subgradient methods for online learning and
        stochasitic optimization." JMLR, 12:2121-2159
        ////
        

        ////
        Apply Nesterov momentum using Lisa Lab's modifications.
        ////
        
Starting training...
Epoch 1 of 100 took 135.101s
  training loss:		2.073839
  validation loss:		1.309727
  validation accuracy:		69.64 %
Epoch 2 of 100 took 135.045s
  training loss:		1.337102
  validation loss:		1.083087
  validation accuracy:		72.60 %
Epoch 3 of 100 took 135.632s
  training loss:		1.169560
  validation loss:		0.962760
  validation accuracy:		74.15 %
Epoch 4 of 100 took 134.974s
  training loss:		1.083723
  validation loss:		0.914778
  validation accuracy:		74.41 %
Epoch 5 of 100 took 134.925s
  training loss:		1.031584
  validation loss:		0.876567
  validation accuracy:		75.54 %
Epoch 6 of 100 took 135.720s
  training loss:		0.997713
  validation loss:		0.854653
  validation accuracy:		76.07 %
Epoch 7 of 100 took 135.006s
  training loss:		0.986652
  validation loss:		0.880513
  validation accuracy:		75.20 %
Epoch 8 of 100 took 135.215s
  training loss:		0.970661
  validation loss:		0.829126
  validation accuracy:		76.41 %
Epoch 9 of 100 took 135.217s
  training loss:		0.967334
  validation loss:		0.839632
  validation accuracy:		76.13 %
Epoch 10 of 100 took 135.002s
  training loss:		0.958619
  validation loss:		0.825296
  validation accuracy:		76.80 %
Epoch 11 of 100 took 134.971s
  training loss:		0.938375
  validation loss:		0.814890
  validation accuracy:		76.82 %
Epoch 12 of 100 took 135.344s
  training loss:		0.928546
  validation loss:		0.806648
  validation accuracy:		76.93 %
Epoch 13 of 100 took 135.105s
  training loss:		0.925052
  validation loss:		0.803207
  validation accuracy:		77.01 %
Epoch 14 of 100 took 134.985s
  training loss:		0.918548
  validation loss:		0.798615
  validation accuracy:		77.31 %
Epoch 15 of 100 took 135.354s
  training loss:		0.920491
  validation loss:		0.802380
  validation accuracy:		77.33 %
Epoch 16 of 100 took 134.993s
  training loss:		0.919900
  validation loss:		0.799103
  validation accuracy:		77.23 %
Epoch 17 of 100 took 135.006s
  training loss:		0.914159
  validation loss:		0.797650
  validation accuracy:		77.02 %
Epoch 18 of 100 took 135.212s
  training loss:		0.912793
  validation loss:		0.799501
  validation accuracy:		76.94 %
Epoch 19 of 100 took 135.315s
  training loss:		0.904405
  validation loss:		0.791918
  validation accuracy:		77.46 %
Epoch 20 of 100 took 135.204s
  training loss:		0.897706
  validation loss:		0.782358
  validation accuracy:		77.72 %
Epoch 21 of 100 took 135.118s
  training loss:		0.892525
  validation loss:		0.786396
  validation accuracy:		77.52 %
Epoch 22 of 100 took 135.351s
  training loss:		0.889192
  validation loss:		0.774008
  validation accuracy:		77.76 %
Epoch 23 of 100 took 135.096s
  training loss:		0.900344
  validation loss:		0.783833
  validation accuracy:		77.77 %
Epoch 24 of 100 took 135.875s
  training loss:		0.882775
  validation loss:		0.777471
  validation accuracy:		77.35 %
Epoch 25 of 100 took 135.107s
  training loss:		0.888239
  validation loss:		0.772417
  validation accuracy:		77.96 %
Epoch 26 of 100 took 135.062s
  training loss:		0.877490
  validation loss:		0.770976
  validation accuracy:		77.80 %
Epoch 27 of 100 took 135.001s
  training loss:		0.876882
  validation loss:		0.776854
  validation accuracy:		77.43 %
Epoch 28 of 100 took 135.011s
  training loss:		0.871920
  validation loss:		0.769248
  validation accuracy:		77.55 %
Epoch 29 of 100 took 135.044s
  training loss:		0.878842
  validation loss:		0.777404
  validation accuracy:		77.68 %
Epoch 30 of 100 took 135.007s
  training loss:		0.869613
  validation loss:		0.766644
  validation accuracy:		77.61 %
Epoch 31 of 100 took 135.262s
  training loss:		0.873230
  validation loss:		0.772843
  validation accuracy:		77.64 %
Epoch 32 of 100 took 135.586s
  training loss:		0.869766
  validation loss:		0.768080
  validation accuracy:		77.75 %
Epoch 33 of 100 took 135.275s
  training loss:		0.872596
  validation loss:		0.761925
  validation accuracy:		77.93 %
Epoch 34 of 100 took 135.226s
  training loss:		0.874516
  validation loss:		0.764250
  validation accuracy:		77.94 %
Epoch 35 of 100 took 135.142s
  training loss:		0.867618
  validation loss:		0.774899
  validation accuracy:		77.55 %
Epoch 36 of 100 took 135.438s
  training loss:		0.864498
  validation loss:		0.766806
  validation accuracy:		77.54 %
Epoch 37 of 100 took 135.478s
  training loss:		0.869717
  validation loss:		0.763607
  validation accuracy:		77.94 %
Epoch 38 of 100 took 135.145s
  training loss:		0.860546
  validation loss:		0.758602
  validation accuracy:		77.86 %
Epoch 39 of 100 took 135.038s
  training loss:		0.864727
  validation loss:		0.765564
  validation accuracy:		77.15 %
Epoch 40 of 100 took 135.379s
  training loss:		0.862001
  validation loss:		0.761265
  validation accuracy:		77.91 %
Epoch 41 of 100 took 135.171s
  training loss:		0.860580
  validation loss:		0.761250
  validation accuracy:		77.72 %
Epoch 42 of 100 took 135.068s
  training loss:		0.866782
  validation loss:		0.764736
  validation accuracy:		77.69 %
Epoch 43 of 100 took 135.100s
  training loss:		0.856770
  validation loss:		0.758821
  validation accuracy:		77.77 %
Epoch 44 of 100 took 135.327s
  training loss:		0.857899
  validation loss:		0.758573
  validation accuracy:		77.78 %
Epoch 45 of 100 took 135.033s
  training loss:		0.856038
  validation loss:		0.758318
  validation accuracy:		77.76 %
Epoch 46 of 100 took 135.247s
  training loss:		0.862926
  validation loss:		0.761115
  validation accuracy:		77.67 %
Epoch 47 of 100 took 135.291s
  training loss:		0.856362
  validation loss:		0.760178
  validation accuracy:		77.63 %
Epoch 48 of 100 took 135.227s
  training loss:		0.854817
  validation loss:		0.756433
  validation accuracy:		77.82 %
Epoch 49 of 100 took 135.070s
  training loss:		0.851422
  validation loss:		0.754814
  validation accuracy:		77.83 %
Epoch 50 of 100 took 135.473s
  training loss:		0.870109
  validation loss:		0.766898
  validation accuracy:		77.51 %
Epoch 51 of 100 took 135.012s
  training loss:		0.869651
  validation loss:		0.763087
  validation accuracy:		77.46 %
Epoch 52 of 100 took 134.967s
  training loss:		0.854466
  validation loss:		0.760463
  validation accuracy:		77.78 %
Epoch 53 of 100 took 134.975s
  training loss:		0.858313
  validation loss:		0.765654
  validation accuracy:		77.63 %
Epoch 54 of 100 took 135.254s
  training loss:		0.858348
  validation loss:		0.758148
  validation accuracy:		77.56 %
Epoch 55 of 100 took 135.044s
  training loss:		0.850820
  validation loss:		0.752582
  validation accuracy:		78.04 %
Epoch 56 of 100 took 135.019s
  training loss:		0.848156
  validation loss:		0.757148
  validation accuracy:		77.81 %
Epoch 57 of 100 took 135.287s
  training loss:		0.846870
  validation loss:		0.751228
  validation accuracy:		77.97 %
Epoch 58 of 100 took 135.066s
  training loss:		0.844423
  validation loss:		0.751188
  validation accuracy:		77.98 %
Epoch 59 of 100 took 135.047s
  training loss:		0.846324
  validation loss:		0.751541
  validation accuracy:		77.77 %
Epoch 60 of 100 took 135.079s
  training loss:		0.846877
  validation loss:		0.751242
  validation accuracy:		77.78 %
Epoch 61 of 100 took 135.164s
  training loss:		0.842664
  validation loss:		0.752014
  validation accuracy:		77.63 %
Epoch 62 of 100 took 135.300s
  training loss:		0.841894
  validation loss:		0.751709
  validation accuracy:		77.67 %
Epoch 63 of 100 took 135.499s
  training loss:		0.844858
  validation loss:		0.752816
  validation accuracy:		77.71 %
Epoch 64 of 100 took 135.142s
  training loss:		0.845347
  validation loss:		0.752344
  validation accuracy:		77.88 %
Epoch 65 of 100 took 135.065s
  training loss:		0.840696
  validation loss:		0.748363
  validation accuracy:		77.95 %
Epoch 66 of 100 took 135.003s
  training loss:		0.838819
  validation loss:		0.754793
  validation accuracy:		77.76 %
Epoch 67 of 100 took 135.061s
  training loss:		0.842081
  validation loss:		0.748594
  validation accuracy:		77.94 %
Epoch 68 of 100 took 135.428s
  training loss:		0.841812
  validation loss:		0.754830
  validation accuracy:		77.78 %
Epoch 69 of 100 took 135.137s
  training loss:		0.841262
  validation loss:		0.748689
  validation accuracy:		78.03 %
Epoch 70 of 100 took 135.144s
  training loss:		0.837786
  validation loss:		0.747297
  validation accuracy:		78.07 %
Epoch 71 of 100 took 135.661s
  training loss:		0.838090
  validation loss:		0.759484
  validation accuracy:		77.73 %
Epoch 72 of 100 took 135.036s
  training loss:		0.844097
  validation loss:		0.749009
  validation accuracy:		77.78 %
Epoch 73 of 100 took 135.100s
  training loss:		0.843574
  validation loss:		0.750193
  validation accuracy:		77.80 %
Epoch 74 of 100 took 135.492s
  training loss:		0.840458
  validation loss:		0.746930
  validation accuracy:		77.91 %
Epoch 75 of 100 took 135.378s
  training loss:		0.838501
  validation loss:		0.745619
  validation accuracy:		78.05 %
Epoch 76 of 100 took 135.337s
  training loss:		0.835532
  validation loss:		0.746275
  validation accuracy:		77.81 %
Epoch 77 of 100 took 135.185s
  training loss:		0.838525
  validation loss:		0.750582
  validation accuracy:		77.91 %
Epoch 78 of 100 took 135.032s
  training loss:		0.838523
  validation loss:		0.743413
  validation accuracy:		78.13 %
Epoch 79 of 100 took 135.568s
  training loss:		0.839999
  validation loss:		0.758570
  validation accuracy:		77.45 %
Epoch 80 of 100 took 134.987s
  training loss:		0.843792
  validation loss:		0.745022
  validation accuracy:		78.16 %
Epoch 81 of 100 took 135.184s
  training loss:		0.838036
  validation loss:		0.750138
  validation accuracy:		78.02 %
Epoch 82 of 100 took 135.065s
  training loss:		0.836437
  validation loss:		0.747850
  validation accuracy:		77.82 %
Epoch 83 of 100 took 135.023s
  training loss:		0.837487
  validation loss:		0.750742
  validation accuracy:		77.89 %
Epoch 84 of 100 took 135.021s
  training loss:		0.836348
  validation loss:		0.752833
  validation accuracy:		77.65 %
Epoch 85 of 100 took 135.419s
  training loss:		0.839448
  validation loss:		0.748215
  validation accuracy:		77.65 %
Epoch 86 of 100 took 135.021s
  training loss:		0.840800
  validation loss:		0.758606
  validation accuracy:		77.40 %
Epoch 87 of 100 took 135.076s
  training loss:		0.837919
  validation loss:		0.746248
  validation accuracy:		78.01 %
Epoch 88 of 100 took 135.011s
  training loss:		0.833597
  validation loss:		0.745929
  validation accuracy:		77.92 %
Epoch 89 of 100 took 135.040s
  training loss:		0.850348
  validation loss:		0.758717
  validation accuracy:		77.57 %
Epoch 90 of 100 took 135.670s
  training loss:		0.884311
  validation loss:		0.769660
  validation accuracy:		77.72 %
Epoch 91 of 100 took 135.057s
  training loss:		0.862552
  validation loss:		0.754056
  validation accuracy:		77.51 %
Epoch 92 of 100 took 135.036s
  training loss:		0.841882
  validation loss:		0.753688
  validation accuracy:		77.58 %
Epoch 93 of 100 took 135.144s
  training loss:		0.840489
  validation loss:		0.748340
  validation accuracy:		77.88 %
Epoch 94 of 100 took 134.960s
  training loss:		0.835787
  validation loss:		0.749857
  validation accuracy:		77.74 %
Epoch 95 of 100 took 135.176s
  training loss:		0.838850
  validation loss:		0.753064
  validation accuracy:		77.53 %
Epoch 96 of 100 took 136.283s
  training loss:		0.844609
  validation loss:		0.758663
  validation accuracy:		77.59 %
Epoch 97 of 100 took 135.057s
  training loss:		0.839432
  validation loss:		0.752331
  validation accuracy:		78.08 %
Epoch 98 of 100 took 135.016s
  training loss:		0.840655
  validation loss:		0.748873
  validation accuracy:		77.76 %
Epoch 99 of 100 took 135.055s
  training loss:		0.838043
  validation loss:		0.753246
  validation accuracy:		77.84 %
Epoch 100 of 100 took 135.010s
  training loss:		0.848958
  validation loss:		0.755577
  validation accuracy:		77.81 %
Final results:
  test loss:			0.742363
  test accuracy:		78.34 %
Using gpu device 0: Tesla K20m (CNMeM is disabled)
/usr/local/python2/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.
  warnings.warn("downsample module has been moved to the pool module.")
Starting...
 Begin with saved parameters? False
 Saved parameters file: ./lminervatriamese_model1455820504.npz
 Saved parameters file exists? True
 Dataset: /phihome/perdue/theano/data/skim_data_convnet_small.hdf5
 Dataset size: 120041441
 Planned number of epochs: 100
 Learning rate: 0.01
 Momentum: 0.9
 L2 regularization penalty scale: 0.0001
Loading data for prediction...
Learning data size: (79775, 3, 50, 50)
Final results:
  test loss:			0.652989
  test accuracy:		78.34 %
   target 1 accuracy:			82.254 %
   target 2 accuracy:			86.178 %
   target 3 accuracy:			81.723 %
   target 4 accuracy:			72.352 %
   target 5 accuracy:			75.039 %
PBS epilogue
